{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbebcc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\ot2107\\appdata\\local\\anaconda3\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\ot2107\\appdata\\local\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\ot2107\\appdata\\local\\anaconda3\\lib\\site-packages (from gensim) (1.11.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ot2107\\appdata\\local\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Loading word2vec model... (this may take a while)\n",
      "Model loaded.\n",
      "   DAT_perf\n",
      "0  0.840487\n",
      "1  0.843097\n",
      "2  0.872506\n",
      "3  0.799434\n",
      "4  0.908836\n",
      "   DAT_perf\n",
      "0  0.913294\n",
      "1  0.880396\n",
      "2  0.877118\n",
      "3  0.899895\n",
      "4  0.933089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
      "C:\\Users\\ot2107\\AppData\\Local\\Temp\\ipykernel_30244\\4047731639.py:149: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[cols] = df[cols].applymap(lambda x: str(x).lower())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SSPT  SSPT_standardized  SSPT_cosine  SSPT_standardized_cosine\n",
      "0  1.013209           0.009591     1.026783                  0.073893\n",
      "1  1.035666           0.960328     1.077662                  1.159764\n",
      "2  1.008889          -0.075669     1.019849                 -0.020189\n",
      "3  1.013648           0.101516     1.016054                 -0.129368\n",
      "4  1.011115          -0.003051     1.023007                  0.032124\n",
      "       SSPT  SSPT_standardized  SSPT_cosine  SSPT_standardized_cosine\n",
      "0  1.015385           0.092685     1.026062                  0.101128\n",
      "1  1.017950          -0.026612     1.019446                 -0.153549\n",
      "2  1.010380           0.013762     1.018857                 -0.030102\n",
      "3  1.023293           0.313542     1.044213                  0.521580\n",
      "4  1.000822          -0.510037     1.000000                 -0.507717\n",
      "DAT_perf                     float64\n",
      "SSPT                         float64\n",
      "creativity_rating_byhuman    float64\n",
      "dtype: object\n",
      "        study name persona specification              variable name  \\\n",
      "0  idea generation       default persona                   DAT_perf   \n",
      "1  idea generation       default persona                       SSPT   \n",
      "2  idea generation       default persona  creativity_rating_byhuman   \n",
      "\n",
      "   correlation between the responses from humans vs. their twins  CI_lower  \\\n",
      "0                                           0.067624             -0.072144   \n",
      "1                                           0.059416             -0.079985   \n",
      "2                                           0.090128             -0.049228   \n",
      "\n",
      "   CI_upper  z-score for correlation between humans vs. their twins  \\\n",
      "0  0.204788                                           0.948189        \n",
      "1  0.196537                                           0.834924        \n",
      "2  0.226043                                           1.268455        \n",
      "\n",
      "   accuracy between humans vs. their twins  mean_human  mean_twin  ...  \\\n",
      "0                                      NaN    0.852485   0.897051  ...   \n",
      "1                                      NaN    1.013301   1.012121  ...   \n",
      "2                                 0.870983    3.198393   3.322436  ...   \n",
      "\n",
      "   effect size based on human  effect size based on twin  domain=social?  \\\n",
      "0                         NaN                        NaN               0   \n",
      "1                         NaN                        NaN               0   \n",
      "2                         NaN                        NaN               0   \n",
      "\n",
      "   domain=cognitive?  replicating know human bias?  preference measure?  \\\n",
      "0                  1                             0                    0   \n",
      "1                  1                             0                    0   \n",
      "2                  1                             0                    0   \n",
      "\n",
      "   stimuli dependent?  knowledge question?  political question?  sample size  \n",
      "0                   0                    0                    0          199  \n",
      "1                   0                    0                    0          200  \n",
      "2                   0                    0                    0          200  \n",
      "\n",
      "[3 rows x 26 columns]\n",
      "   TWIN_ID variable_name     value respondent_type       study_name  \\\n",
      "0        3      DAT_perf  0.840487           human  idea generation   \n",
      "1        4      DAT_perf  0.843097           human  idea generation   \n",
      "2       11      DAT_perf  0.872506           human  idea generation   \n",
      "3       21      DAT_perf  0.799434           human  idea generation   \n",
      "4       22      DAT_perf  0.908836           human  idea generation   \n",
      "\n",
      "  specification_name  \n",
      "0    default persona  \n",
      "1    default persona  \n",
      "2    default persona  \n",
      "3    default persona  \n",
      "4    default persona  \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f, norm, pearsonr, ttest_rel\n",
    "\n",
    "!pip install --upgrade gensim\n",
    "import re\n",
    "from itertools import permutations\n",
    "\n",
    "import gensim.downloader as api\n",
    "import scipy.stats as stats\n",
    "from gensim.models import KeyedVectors\n",
    "from scipy.spatial.distance import cosine, euclidean, pdist\n",
    "\n",
    "# Load data\n",
    "study_name = \"idea generation\"\n",
    "specification_name = \"default persona\"\n",
    "human_file = f\"{study_name} human data labels anonymized.csv\"\n",
    "twin_file = f\"{study_name} twins data labels anonymized.csv\"\n",
    "df_human = pd.read_csv(human_file, header=0, skiprows=[1, 2])\n",
    "df_twin = pd.read_csv(twin_file, header=0, skiprows=[1])\n",
    "\n",
    "# creativity ratings:\n",
    "human_file = f\"{study_name} human data creativity ratings.csv\"\n",
    "twin_file = f\"{study_name} twins data creativity ratings.csv\"\n",
    "creativity_human = pd.read_csv(human_file, header=0)\n",
    "creativity_twin = pd.read_csv(twin_file, header=0)\n",
    "\n",
    "# pull out just the ID + creativity columns\n",
    "creat_col = creativity_human[\n",
    "    [\n",
    "        \"TWIN_ID\",\n",
    "        \"creativity_rating_byhuman\",\n",
    "        \"creativity_rating_byhuman_partial\",\n",
    "        \"creativity_rating_byhuman_full\",\n",
    "        \"creativity_rating_bytwins\",\n",
    "    ]\n",
    "]\n",
    "# merge into df_human (left‐join so you keep all rows in df_human)\n",
    "df_human = df_human.merge(creat_col, on=\"TWIN_ID\", how=\"left\")\n",
    "creat_col = creativity_twin[\n",
    "    [\n",
    "        \"TWIN_ID\",\n",
    "        \"creativity_rating_byhuman\",\n",
    "        \"creativity_rating_byhuman_partial\",\n",
    "        \"creativity_rating_byhuman_full\",\n",
    "        \"creativity_rating_bytwins\",\n",
    "    ]\n",
    "]\n",
    "# merge into df_human (left‐join so you keep all rows in df_human)\n",
    "df_twin = df_twin.merge(creat_col, on=\"TWIN_ID\", how=\"left\")\n",
    "\n",
    "# previous human data:\n",
    "wave1_human = pd.read_csv(\"wave 1 scores.csv\", header=0)\n",
    "wave2_human = pd.read_csv(\"wave 2 scores.csv\", header=0)\n",
    "wave3_human = pd.read_csv(\"wave 3 scores.csv\", header=0)\n",
    "# pull out relevant columns\n",
    "creat_col = wave2_human[[\"TWIN_ID\", \"score_forwardflow\"]]\n",
    "# merge into df_human (left‐join so you keep all rows in df_human)\n",
    "df_human = df_human.merge(creat_col, on=\"TWIN_ID\", how=\"left\")\n",
    "# add also to twins, for symmetry:\n",
    "df_twin = df_twin.merge(creat_col, on=\"TWIN_ID\", how=\"left\")\n",
    "# Load the Word2Vec model (Google News model; this will download the model if not already available)\n",
    "print(\"Loading word2vec model... (this may take a while)\")\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "\n",
    "#########################\n",
    "# create new relevant columns: DAT\n",
    "text_cols = [f\"Q74_{i}\" for i in range(1, 11)]\n",
    "\n",
    "\n",
    "def compute_dat_perf_from_cols(row):\n",
    "    # 1) grab the 10 entries, lowercase and drop any NaN/empty\n",
    "    tokens = [\n",
    "        str(row[col]).lower().strip()\n",
    "        for col in text_cols\n",
    "        if pd.notna(row[col]) and str(row[col]).strip() != \"\"\n",
    "    ]\n",
    "    # 2) look up embeddings (skip tokens not in vocab)\n",
    "    vecs = [model[w] for w in tokens if w in model.key_to_index]\n",
    "    # 3) must have at least 7 embeddings\n",
    "    if len(vecs) < 7:\n",
    "        return np.nan\n",
    "    # 4) stack the first 7 into a matrix\n",
    "    mat = np.vstack(vecs[:7])\n",
    "    # 5) compute all pairwise Euclidean distances and return the mean\n",
    "    #    dists = pdist(mat, metric='euclidean')\n",
    "    dists = pdist(mat, metric=\"cosine\")\n",
    "    return dists.mean()\n",
    "\n",
    "\n",
    "# apply it directly over the 10 columns\n",
    "df_human[\"DAT_perf\"] = df_human[text_cols].apply(compute_dat_perf_from_cols, axis=1)\n",
    "df_twin[\"DAT_perf\"] = df_twin[text_cols].apply(compute_dat_perf_from_cols, axis=1)\n",
    "# quick check\n",
    "print(df_human[[\"DAT_perf\"]].head())\n",
    "print(df_twin[[\"DAT_perf\"]].head())\n",
    "###############################\n",
    "\n",
    "\n",
    "#########################\n",
    "# create new relevant columns: SSPT\n",
    "def compute_circuitousness_euclidean(words, model):\n",
    "    \"\"\"Euclidean‐based circuitousness over 5 word embeddings.\"\"\"\n",
    "    if len(words) != len(set(words)):\n",
    "        return np.nan\n",
    "    embs = []\n",
    "    for w in words:\n",
    "        toks = [t for t in str(w).lower().split() if t]\n",
    "        vecs = [model[t] for t in toks if t in model.key_to_index]\n",
    "        if not vecs:\n",
    "            return np.nan\n",
    "        embs.append(np.mean(vecs, axis=0))\n",
    "    if len(embs) != 5:\n",
    "        return np.nan\n",
    "    # original path\n",
    "    orig = sum(euclidean(embs[i], embs[i + 1]) for i in range(4))\n",
    "    best = np.inf\n",
    "    for perm in permutations(embs[1:4]):\n",
    "        path = [embs[0]] + list(perm) + [embs[4]]\n",
    "        length = sum(euclidean(path[i], path[i + 1]) for i in range(4))\n",
    "        best = min(best, length)\n",
    "    return orig / best if best > 0 else np.nan\n",
    "\n",
    "\n",
    "def compute_circuitousness_cosine(words, model):\n",
    "    \"\"\"Cosine‐based circuitousness over 5 word embeddings.\"\"\"\n",
    "    if len(words) != len(set(words)):\n",
    "        return np.nan\n",
    "    embs = []\n",
    "    for w in words:\n",
    "        toks = [t for t in str(w).lower().split() if t]\n",
    "        vecs = [model[t] for t in toks if t in model.key_to_index]\n",
    "        if not vecs:\n",
    "            return np.nan\n",
    "        embs.append(np.mean(vecs, axis=0))\n",
    "    if len(embs) != 5:\n",
    "        return np.nan\n",
    "    orig = sum(cosine(embs[i], embs[i + 1]) for i in range(4))\n",
    "    best = np.inf\n",
    "    for perm in permutations(embs[1:4]):\n",
    "        path = [embs[0]] + list(perm) + [embs[4]]\n",
    "        length = sum(cosine(path[i], path[i + 1]) for i in range(4))\n",
    "        best = min(best, length)\n",
    "    return orig / best if best > 0 else np.nan\n",
    "\n",
    "\n",
    "def add_sspt_all(df, model):\n",
    "    prefixes = [1, 2, 4, 5, 7]\n",
    "    eu_cols, co_cols = [], []\n",
    "\n",
    "    # compute raw circuitousness for each metric & task\n",
    "    for p in prefixes:\n",
    "        cols = [f\"{p}_Q30_{i}\" for i in range(1, 6)]\n",
    "        df[cols] = df[cols].applymap(lambda x: str(x).lower())\n",
    "\n",
    "        e_col = f\"circuitousness_task{p}_euclid\"\n",
    "        c_col = f\"circuitousness_task{p}_cosine\"\n",
    "        eu_cols.append(e_col)\n",
    "        co_cols.append(c_col)\n",
    "\n",
    "        df[e_col] = df[cols].apply(\n",
    "            lambda r: compute_circuitousness_euclidean(r.tolist(), model), axis=1\n",
    "        )\n",
    "        df[c_col] = df[cols].apply(\n",
    "            lambda r: compute_circuitousness_cosine(r.tolist(), model), axis=1\n",
    "        )\n",
    "\n",
    "    # raw SSPT\n",
    "    df[\"SSPT\"] = df[eu_cols].mean(axis=1)\n",
    "    df[\"n_non_na_tasks_SSPT\"] = df[eu_cols].notna().sum(axis=1)\n",
    "    df[\"SSPT_cosine\"] = df[co_cols].mean(axis=1)\n",
    "    df[\"n_non_na_tasks_SSPT_cosine\"] = df[co_cols].notna().sum(axis=1)\n",
    "\n",
    "    # standardize per task\n",
    "    stats_eu = df[eu_cols].agg([\"mean\", \"std\"])\n",
    "    stats_co = df[co_cols].agg([\"mean\", \"std\"])\n",
    "\n",
    "    z_eu, z_co = [], []\n",
    "    for col in eu_cols:\n",
    "        zc = f\"{col}_z\"\n",
    "        df[zc] = (df[col] - stats_eu.loc[\"mean\", col]) / stats_eu.loc[\"std\", col]\n",
    "        z_eu.append(zc)\n",
    "    for col in co_cols:\n",
    "        zc = f\"{col}_z\"\n",
    "        df[zc] = (df[col] - stats_co.loc[\"mean\", col]) / stats_co.loc[\"std\", col]\n",
    "        z_co.append(zc)\n",
    "\n",
    "    # standardized SSPT\n",
    "    df[\"SSPT_standardized\"] = df[z_eu].mean(axis=1)\n",
    "    df[\"n_non_na_tasks_SSPT_standardized\"] = df[z_eu].notna().sum(axis=1)\n",
    "    df[\"SSPT_standardized_cosine\"] = df[z_co].mean(axis=1)\n",
    "    df[\"n_non_na_tasks_SSPT_standardized_cosine\"] = df[z_co].notna().sum(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply to both datasets\n",
    "df_human = add_sspt_all(df_human, model)\n",
    "df_twin = add_sspt_all(df_twin, model)\n",
    "\n",
    "# Quick peek\n",
    "print(df_human[[\"SSPT\", \"SSPT_standardized\", \"SSPT_cosine\", \"SSPT_standardized_cosine\"]].head())\n",
    "\n",
    "print(df_twin[[\"SSPT\", \"SSPT_standardized\", \"SSPT_cosine\", \"SSPT_standardized_cosine\"]].head())\n",
    "\n",
    "\n",
    "#########################################\n",
    "\n",
    "\n",
    "# Remove any leading apostrophes and coerce to float\n",
    "df_human[\"DAT_perf\"] = pd.to_numeric(\n",
    "    df_human[\"DAT_perf\"].astype(str).str.lstrip(\"'\"), errors=\"coerce\"\n",
    ")\n",
    "\n",
    "df_twin[\"DAT_perf\"] = pd.to_numeric(\n",
    "    df_twin[\"DAT_perf\"].astype(str).str.lstrip(\"'\"), errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Do the same for any other columns you expect to be numeric\n",
    "for col in [\"SSPT\", \"creativity_rating_byhuman\"] + [\n",
    "    c for c in df_human if c.startswith(\"circuitousness_task\")\n",
    "]:\n",
    "    df_human[col] = pd.to_numeric(df_human[col], errors=\"coerce\")\n",
    "    df_twin[col] = pd.to_numeric(df_twin[col], errors=\"coerce\")\n",
    "\n",
    "# Confirm\n",
    "print(df_human[[\"DAT_perf\", \"SSPT\", \"creativity_rating_byhuman\"]].dtypes)\n",
    "\n",
    "df_twin.to_csv(\"idea_generation_twins_processed.csv\", index=False)\n",
    "df_human.to_csv(\"idea_generation_human_processed.csv\", index=False)\n",
    "\n",
    "df_human = df_human.set_index(\"TWIN_ID\")\n",
    "df_twin = df_twin.set_index(\"TWIN_ID\")\n",
    "\n",
    "\n",
    "##################now proceed with standard meta-analysis steps\n",
    "# define relevant columns:\n",
    "# condition variable names:\n",
    "condition_vars = [\"\"]\n",
    "# Check if we have a real condition var\n",
    "if condition_vars and condition_vars[0].strip():\n",
    "    cond = condition_vars[0]\n",
    "    cond_h = f\"{cond}_human\"\n",
    "    cond_t = f\"{cond}_twin\"\n",
    "    cond_exists = True\n",
    "else:\n",
    "    cond_exists = False\n",
    "\n",
    "# raw responses:\n",
    "# raw_vars = []\n",
    "# raw_vars_min = [1]*20\n",
    "# raw_vars_max = [5]*20\n",
    "# raw responses: domain=social?\n",
    "# raw_vars_social=[1]*20\n",
    "# raw_vars_social_map = dict(zip(raw_vars, raw_vars_social))\n",
    "# raw responses: domain=cognitive?\n",
    "# raw_vars_cognitive=[0]*20\n",
    "# raw_vars_cognitive_map = dict(zip(raw_vars, raw_vars_cognitive))\n",
    "# raw responses: replicating know human bias?\n",
    "# raw_vars_known=[0]*20\n",
    "# raw_vars_known_map = dict(zip(raw_vars, raw_vars_known))\n",
    "# raw responses: preference measure?\n",
    "# raw_vars_pref=[1]*20\n",
    "# raw_vars_pref_map = dict(zip(raw_vars, raw_vars_pref))\n",
    "# raw responses: stimuli dependent?\n",
    "# raw_vars_stim=[1]*20\n",
    "# raw_vars_stim_map = dict(zip(raw_vars, raw_vars_stim))\n",
    "\n",
    "# DVs:\n",
    "DV_vars = [\"DAT_perf\", \"SSPT\", \"creativity_rating_byhuman\"]\n",
    "DV_vars_min = [\"nan\", \"nan\", 1]\n",
    "DV_vars_max = [\"nan\", \"nan\", 5]\n",
    "# DVs: domain=social?\n",
    "DV_vars_social = [0] * 3\n",
    "DV_vars_social_map = dict(zip(DV_vars, DV_vars_social))\n",
    "# DVs: domain=cognitive?\n",
    "DV_vars_cognitive = [1] * 3\n",
    "DV_vars_cognitive_map = dict(zip(DV_vars, DV_vars_cognitive))\n",
    "# DVs: replicating know human bias?\n",
    "DV_vars_known = [0] * 3\n",
    "DV_vars_known_map = dict(zip(DV_vars, DV_vars_known))\n",
    "# DVs: preference measure?\n",
    "DV_vars_pref = [0] * 3\n",
    "DV_vars_pref_map = dict(zip(DV_vars, DV_vars_pref))\n",
    "# DVs: stimuli dependent?\n",
    "DV_vars_stim = [0] * 3\n",
    "DV_vars_stim_map = dict(zip(DV_vars, DV_vars_stim))\n",
    "# DVs: knowledge question?\n",
    "DV_vars_know = [0] * 3\n",
    "DV_vars_know_map = dict(zip(DV_vars, DV_vars_know))\n",
    "# DVs: political question?\n",
    "DV_vars_politics = [0] * 3\n",
    "DV_vars_politics_map = dict(zip(DV_vars, DV_vars_politics))\n",
    "\n",
    "# merging key\n",
    "merge_key = [\"TWIN_ID\"]\n",
    "\n",
    "# Merge on TWIN_ID\n",
    "df = pd.merge(df_human, df_twin, on=merge_key, suffixes=(\"_human\", \"_twin\"))\n",
    "\n",
    "# Fix dtypes\n",
    "# for var in raw_vars + DV_vars:\n",
    "for var in DV_vars:\n",
    "    df[f\"{var}_human\"] = pd.to_numeric(df[f\"{var}_human\"], errors=\"coerce\")\n",
    "    df[f\"{var}_twin\"] = pd.to_numeric(df[f\"{var}_twin\"], errors=\"coerce\")\n",
    "\n",
    "# build min/max maps from both raw_vars and DV_vars\n",
    "min_map = {v: mn for v, mn in zip(DV_vars, DV_vars_min)}\n",
    "# min_map = {v: mn for v, mn in zip(raw_vars,      raw_vars_min)}\n",
    "# min_map.update({v: mn for v, mn in zip(DV_vars,   DV_vars_min)})\n",
    "\n",
    "max_map = {v: mx for v, mx in zip(DV_vars, DV_vars_max)}\n",
    "# max_map = {v: mx for v, mx in zip(raw_vars,      raw_vars_max)}\n",
    "# max_map.update({v: mx for v, mx in zip(DV_vars,   DV_vars_max)})\n",
    "\n",
    "# now add _min and _max columns for every variable in the union\n",
    "for var in min_map:\n",
    "    df[f\"{var}_min\"] = min_map[var]\n",
    "    df[f\"{var}_max\"] = max_map[var]\n",
    "\n",
    "# Compute results\n",
    "results = []\n",
    "# for var in raw_vars:\n",
    "#     col_h = f\"{var}_human\"\n",
    "#     col_t = f\"{var}_twin\"\n",
    "#     min_col = f\"{var}_min\"\n",
    "#     max_col = f\"{var}_max\"\n",
    "#     if cond_exists:\n",
    "#         cols = [col_h, col_t, cond_h, cond_t,min_col,max_col]\n",
    "#     else:\n",
    "#         cols = [col_h, col_t,min_col,max_col]\n",
    "#     pair = (\n",
    "#     df[cols]\n",
    "#       .dropna(subset=[col_h, col_t])\n",
    "#     )\n",
    "#     min_val = pair[min_col].iloc[0]\n",
    "#     max_val = pair[max_col].iloc[0]\n",
    "#     n    = len(pair)\n",
    "#     if n >= 4:\n",
    "#         r, _    = pearsonr(pair[col_h], pair[col_t])\n",
    "#         z_f     = np.arctanh(r)\n",
    "#         se      = 1 / np.sqrt(n - 3)\n",
    "#         z_crit  = norm.ppf(0.975)\n",
    "#         lo_z, hi_z = z_f - z_crit*se, z_f + z_crit*se\n",
    "#         lo_r, hi_r = np.tanh(lo_z), np.tanh(hi_z)\n",
    "#         z_score    = z_f / se\n",
    "#         # Accuracy = mean absolute diff / range\n",
    "#         if pd.isna(min_val) or pd.isna(max_val) or max_val == min_val:\n",
    "#             accuracy = np.nan\n",
    "#         else:\n",
    "#             # compute mean absolute difference\n",
    "#             abs_diff      = np.abs(pair[col_h] - pair[col_t])\n",
    "#             mean_abs_diff = abs_diff.mean()\n",
    "#             accuracy      = 1 - mean_abs_diff / (max_val - min_val)\n",
    "\n",
    "#         mean_h = pair[col_h].mean()\n",
    "#         mean_t = pair[col_t].mean()\n",
    "\n",
    "#         # Paired t‐test\n",
    "#         t_stat, p_val = ttest_rel(pair[col_h], pair[col_t])\n",
    "\n",
    "#         std_h = pair[col_h].std(ddof=1)\n",
    "#         std_t = pair[col_t].std(ddof=1)\n",
    "\n",
    "#          # F‐test for equal variances\n",
    "#         df1 = df2 = n - 1\n",
    "#         f_stat = (std_h**2 / std_t**2) if std_t>0 else np.nan\n",
    "\n",
    "#         # two‐tailed p‐value:\n",
    "#         if not np.isnan(f_stat):\n",
    "#             p_f = 2 * min(f.cdf(f_stat, df1, df2),\n",
    "#                           1 - f.cdf(f_stat, df1, df2))\n",
    "#         else:\n",
    "#             p_f = np.nan\n",
    "\n",
    "#         # Effect sizes (Cohen's d) across conditions\n",
    "#         #    For humans:\n",
    "#         if cond_exists and len(pair)>3:\n",
    "#             levels_h = pair[cond_h].unique()\n",
    "#             if len(levels_h) == 2:\n",
    "#                 g1 = pair.loc[pair[cond_h]==levels_h[0], col_h]\n",
    "#                 g2 = pair.loc[pair[cond_h]==levels_h[1], col_h]\n",
    "#                 n1, n2 = len(g1), len(g2)\n",
    "#                 # pooled sd\n",
    "#                 s_pool = np.sqrt(((n1-1)*g1.var(ddof=1)+(n2-1)*g2.var(ddof=1)) / (n1+n2-2))\n",
    "#                 d_human = (g1.mean() - g2.mean()) / s_pool if s_pool>0 else np.nan\n",
    "#             else:\n",
    "#                 d_human = np.nan\n",
    "#         else:\n",
    "#             d_human = np.nan\n",
    "\n",
    "#         #    For twins:\n",
    "#         if cond_exists and len(pair)>3:\n",
    "#             levels_t = pair[cond_t].unique()\n",
    "#             if cond_exists and len(levels_t) == 2:\n",
    "#                 g1 = pair.loc[pair[cond_t]==levels_t[0], col_t]\n",
    "#                 g2 = pair.loc[pair[cond_t]==levels_t[1], col_t]\n",
    "#                 n1, n2 = len(g1), len(g2)\n",
    "#                 s_pool = np.sqrt(((n1-1)*g1.var(ddof=1)+(n2-1)*g2.var(ddof=1)) / (n1+n2-2))\n",
    "#                 d_twin = (g1.mean() - g2.mean()) / s_pool if s_pool>0 else np.nan\n",
    "#             else:\n",
    "#                 d_twin = np.nan\n",
    "#         else:\n",
    "#             d_twin = np.nan\n",
    "#     else:\n",
    "#         r = lo_r = hi_r = z_score = accuracy = mean_h = mean_t = t_stat = p_val = std_h = std_t = f_stat = p_f = np.nan\n",
    "#         d_human = d_twin = np.nan\n",
    "\n",
    "\n",
    "#     results.append({\n",
    "#         'study name': study_name,\n",
    "#         'variable name': var,\n",
    "#         'variable type (raw response/DV)':     'raw',\n",
    "#         'correlation between the responses from humans vs. their twins':        r,\n",
    "#         'CI_lower': lo_r,\n",
    "#         'CI_upper': hi_r,\n",
    "#         'z-score for correlation between humans vs. their twins':  z_score,\n",
    "#         'accuracy between humans vs. their twins': accuracy,\n",
    "#         'mean_human': mean_h,\n",
    "#         'mean_twin': mean_t,\n",
    "#         'paired t-test t-stat': t_stat,\n",
    "#         'paired t-test p-value': p_val,\n",
    "#         'std_human': std_h,\n",
    "#         'std_twin': std_t,\n",
    "#         'variance test F-stat': f_stat,\n",
    "#         'variance test p-value': p_f,\n",
    "#         'effect size based on human': d_human,\n",
    "#         'effect size based on twin': d_twin,\n",
    "#         'domain=social?':raw_vars_social_map.get(var, np.nan),\n",
    "#         'domain=cognitive?':raw_vars_cognitive_map.get(var, np.nan),\n",
    "#         'replicating know human bias?':raw_vars_known_map.get(var, np.nan),\n",
    "#         'preference measure?':raw_vars_pref_map.get(var, np.nan),\n",
    "#         'stimuli dependent?':raw_vars_stim_map.get(var, np.nan),\n",
    "#         'sample size':        n\n",
    "#     })\n",
    "\n",
    "for var in DV_vars:\n",
    "    col_h = f\"{var}_human\"\n",
    "    col_t = f\"{var}_twin\"\n",
    "    min_col = f\"{var}_min\"\n",
    "    max_col = f\"{var}_max\"\n",
    "    if cond_exists:\n",
    "        cols = [col_h, col_t, cond_h, cond_t, min_col, max_col]\n",
    "    else:\n",
    "        cols = [col_h, col_t, min_col, max_col]\n",
    "    pair = df[cols].dropna(subset=[col_h, col_t])\n",
    "    min_val = pair[min_col].iloc[0]\n",
    "    max_val = pair[max_col].iloc[0]\n",
    "    n = len(pair)\n",
    "    if n >= 4:\n",
    "        r, _ = pearsonr(pair[col_h], pair[col_t])\n",
    "        z_f = np.arctanh(r)\n",
    "        se = 1 / np.sqrt(n - 3)\n",
    "        z_crit = norm.ppf(0.975)\n",
    "        lo_z, hi_z = z_f - z_crit * se, z_f + z_crit * se\n",
    "        lo_r, hi_r = np.tanh(lo_z), np.tanh(hi_z)\n",
    "        z_score = z_f / se\n",
    "        # Accuracy = mean absolute diff / range\n",
    "        if pd.isna(min_val) or pd.isna(max_val) or max_val == min_val:\n",
    "            accuracy = np.nan\n",
    "        else:\n",
    "            # compute mean absolute difference\n",
    "            abs_diff = np.abs(pair[col_h] - pair[col_t])\n",
    "            mean_abs_diff = abs_diff.mean()\n",
    "            accuracy = 1 - mean_abs_diff / (max_val - min_val)\n",
    "\n",
    "        mean_h = pair[col_h].mean()\n",
    "        mean_t = pair[col_t].mean()\n",
    "\n",
    "        # Paired t‐test\n",
    "        t_stat, p_val = ttest_rel(pair[col_h], pair[col_t])\n",
    "\n",
    "        std_h = pair[col_h].std(ddof=1)\n",
    "        std_t = pair[col_t].std(ddof=1)\n",
    "\n",
    "        # F‐test for equal variances\n",
    "        df1 = df2 = n - 1\n",
    "        f_stat = (std_h**2 / std_t**2) if std_t > 0 else np.nan\n",
    "        # two‐tailed p‐value:\n",
    "        if not np.isnan(f_stat):\n",
    "            p_f = 2 * min(f.cdf(f_stat, df1, df2), 1 - f.cdf(f_stat, df1, df2))\n",
    "        else:\n",
    "            p_f = np.nan\n",
    "\n",
    "        # Effect sizes (Cohen's d) across conditions\n",
    "        #    For humans:\n",
    "        if cond_exists and len(pair) > 3:\n",
    "            levels_h = pair[cond_h].unique()\n",
    "            if len(levels_h) == 2:\n",
    "                g1 = pair.loc[pair[cond_h] == levels_h[0], col_h]\n",
    "                g2 = pair.loc[pair[cond_h] == levels_h[1], col_h]\n",
    "                n1, n2 = len(g1), len(g2)\n",
    "                # pooled sd\n",
    "                s_pool = np.sqrt(\n",
    "                    ((n1 - 1) * g1.var(ddof=1) + (n2 - 1) * g2.var(ddof=1)) / (n1 + n2 - 2)\n",
    "                )\n",
    "                d_human = (g1.mean() - g2.mean()) / s_pool if s_pool > 0 else np.nan\n",
    "            else:\n",
    "                d_human = np.nan\n",
    "        else:\n",
    "            d_human = np.nan\n",
    "\n",
    "        #    For twins:\n",
    "        if cond_exists and len(pair) > 3:\n",
    "            levels_t = pair[cond_t].unique()\n",
    "            if cond_exists and len(levels_t) == 2:\n",
    "                g1 = pair.loc[pair[cond_t] == levels_t[0], col_t]\n",
    "                g2 = pair.loc[pair[cond_t] == levels_t[1], col_t]\n",
    "                n1, n2 = len(g1), len(g2)\n",
    "                s_pool = np.sqrt(\n",
    "                    ((n1 - 1) * g1.var(ddof=1) + (n2 - 1) * g2.var(ddof=1)) / (n1 + n2 - 2)\n",
    "                )\n",
    "                d_twin = (g1.mean() - g2.mean()) / s_pool if s_pool > 0 else np.nan\n",
    "            else:\n",
    "                d_twin = np.nan\n",
    "        else:\n",
    "            d_twin = np.nan\n",
    "    else:\n",
    "        r = lo_r = hi_r = z_score = accuracy = mean_h = mean_t = t_stat = p_val = std_h = std_t = (\n",
    "            f_stat\n",
    "        ) = p_f = np.nan\n",
    "        d_human = d_twin = np.nan\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"study name\": study_name,\n",
    "            \"persona specification\": specification_name,\n",
    "            \"variable name\": var,\n",
    "            #        'variable type (raw response/DV)':     'DV',\n",
    "            \"correlation between the responses from humans vs. their twins\": r,\n",
    "            \"CI_lower\": lo_r,\n",
    "            \"CI_upper\": hi_r,\n",
    "            \"z-score for correlation between humans vs. their twins\": z_score,\n",
    "            \"accuracy between humans vs. their twins\": accuracy,\n",
    "            \"mean_human\": mean_h,\n",
    "            \"mean_twin\": mean_t,\n",
    "            \"paired t-test t-stat\": t_stat,\n",
    "            \"paired t-test p-value\": p_val,\n",
    "            \"std_human\": std_h,\n",
    "            \"std_twin\": std_t,\n",
    "            \"variance test F-stat\": f_stat,\n",
    "            \"variance test p-value\": p_f,\n",
    "            \"effect size based on human\": d_human,\n",
    "            \"effect size based on twin\": d_twin,\n",
    "            \"domain=social?\": DV_vars_social_map.get(var, np.nan),\n",
    "            \"domain=cognitive?\": DV_vars_cognitive_map.get(var, np.nan),\n",
    "            \"replicating know human bias?\": DV_vars_known_map.get(var, np.nan),\n",
    "            \"preference measure?\": DV_vars_pref_map.get(var, np.nan),\n",
    "            \"stimuli dependent?\": DV_vars_stim_map.get(var, np.nan),\n",
    "            \"knowledge question?\": DV_vars_know_map.get(var, np.nan),\n",
    "            \"political question?\": DV_vars_politics_map.get(var, np.nan),\n",
    "            \"sample size\": n,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# results DataFrame\n",
    "corr_df = pd.DataFrame(results)\n",
    "print(corr_df)\n",
    "\n",
    "# save output as csv - unit of observation is comparison between humans and twins:\n",
    "out_file = f\"{study_name} {specification_name} meta analysis.csv\"\n",
    "corr_df.to_csv(out_file, index=False)\n",
    "\n",
    "\n",
    "#####participant-level data:\n",
    "def make_long(df, respondent_type):\n",
    "    # pick off TWIN_ID + the DVs, then melt\n",
    "    long = df[[\"TWIN_ID\"] + DV_vars].melt(\n",
    "        id_vars=\"TWIN_ID\", value_vars=DV_vars, var_name=\"variable_name\", value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    long[\"respondent_type\"] = respondent_type\n",
    "    long[\"study_name\"] = study_name\n",
    "    long[\"specification_name\"] = specification_name\n",
    "    return long\n",
    "\n",
    "\n",
    "#########################unique to this study:\n",
    "# turn the index back into a column so melt can see it\n",
    "df_human.reset_index(inplace=True)\n",
    "df_twin.reset_index(inplace=True)\n",
    "###################\n",
    "\n",
    "# build the two halves\n",
    "long_h = make_long(df_human, \"human\")\n",
    "long_t = make_long(df_twin, \"twin\")\n",
    "\n",
    "# stack them\n",
    "df_long = pd.concat([long_h, long_t], ignore_index=True)\n",
    "\n",
    "print(df_long.head())\n",
    "# save output as csv - unit of observation is TWIN_ID:\n",
    "out_file = f\"{study_name} {specification_name} meta analysis individual level.csv\"\n",
    "df_long.to_csv(out_file, index=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f746f800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: use cosine distance instead of Euclidean distance in SSPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68f3ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ means summary written with columns: ['DAT_perf_human_mean', 'score_forwardflow_human_mean', 'SSPT_human_mean', 'SSPT_cosine_human_mean', 'SSPT_standardized_human_mean', 'SSPT_standardized_cosine_human_mean', 'creativity_rating_byhuman_human_mean', 'creativity_rating_byhuman_partial_human_mean', 'creativity_rating_byhuman_full_human_mean', 'DAT_perf_twin_mean', 'SSPT_twin_mean', 'SSPT_cosine_twin_mean', 'SSPT_standardized_twin_mean', 'SSPT_standardized_cosine_twin_mean', 'creativity_rating_bytwins_twin_mean', 'creativity_rating_byhuman_twin_mean', 'creativity_rating_byhuman_partial_twin_mean', 'creativity_rating_byhuman_full_twin_mean']\n",
      "→ std‐summary written with columns: ['DAT_perf_human_std', 'score_forwardflow_human_std', 'SSPT_human_std', 'SSPT_cosine_human_std', 'SSPT_standardized_human_std', 'SSPT_standardized_cosine_human_std', 'creativity_rating_byhuman_human_std', 'creativity_rating_byhuman_partial_human_std', 'creativity_rating_byhuman_full_human_std', 'DAT_perf_twin_std', 'SSPT_twin_std', 'SSPT_cosine_twin_std', 'SSPT_standardized_twin_std', 'SSPT_standardized_cosine_twin_std', 'creativity_rating_bytwins_twin_std', 'creativity_rating_byhuman_twin_std', 'creativity_rating_byhuman_partial_twin_std', 'creativity_rating_byhuman_full_twin_std']\n",
      "→ correlation matrix written with index/cols: ['DAT_perf_human', 'score_forwardflow_human', 'SSPT_human', 'SSPT_cosine_human', 'SSPT_standardized_human', 'SSPT_standardized_cosine_human', 'creativity_rating_byhuman_human', 'creativity_rating_byhuman_partial_human', 'creativity_rating_byhuman_full_human', 'DAT_perf_twin', 'SSPT_twin', 'SSPT_cosine_twin', 'SSPT_standardized_twin', 'SSPT_standardized_cosine_twin', 'creativity_rating_bytwins_twin', 'creativity_rating_byhuman_twin', 'creativity_rating_byhuman_partial_twin', 'creativity_rating_byhuman_full_twin']\n",
      "→ p-value matrix written with index/cols: ['DAT_perf_human', 'score_forwardflow_human', 'SSPT_human', 'SSPT_cosine_human', 'SSPT_standardized_human', 'SSPT_standardized_cosine_human', 'creativity_rating_byhuman_human', 'creativity_rating_byhuman_partial_human', 'creativity_rating_byhuman_full_human', 'DAT_perf_twin', 'SSPT_twin', 'SSPT_cosine_twin', 'SSPT_standardized_twin', 'SSPT_standardized_cosine_twin', 'creativity_rating_bytwins_twin', 'creativity_rating_byhuman_twin', 'creativity_rating_byhuman_partial_twin', 'creativity_rating_byhuman_full_twin']\n"
     ]
    }
   ],
   "source": [
    "# replicate pre-registered analysis:\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# 1) define the exact order you want\n",
    "vars_list_human = [\n",
    "    \"DAT_perf\",\n",
    "    \"score_forwardflow\",\n",
    "    \"SSPT\",\n",
    "    \"SSPT_cosine\",\n",
    "    \"SSPT_standardized\",\n",
    "    \"SSPT_standardized_cosine\",\n",
    "    \"creativity_rating_byhuman\",\n",
    "    \"creativity_rating_byhuman_partial\",\n",
    "    \"creativity_rating_byhuman_full\",\n",
    "]\n",
    "human_cols = [f\"{v}_human\" for v in vars_list_human]\n",
    "vars_list_twin = [\n",
    "    \"DAT_perf\",\n",
    "    \"SSPT\",\n",
    "    \"SSPT_cosine\",\n",
    "    \"SSPT_standardized\",\n",
    "    \"SSPT_standardized_cosine\",\n",
    "    \"creativity_rating_bytwins\",\n",
    "    \"creativity_rating_byhuman\",\n",
    "    \"creativity_rating_byhuman_partial\",\n",
    "    \"creativity_rating_byhuman_full\",\n",
    "]\n",
    "twin_cols = [f\"{v}_twin\" for v in vars_list_twin]\n",
    "all_cols = human_cols + twin_cols\n",
    "\n",
    "# --- 2) Means summary, in the same order ---\n",
    "mean_cols = [f\"{v}_human_mean\" for v in vars_list_human] + [\n",
    "    f\"{v}_twin_mean\" for v in vars_list_twin\n",
    "]\n",
    "means = {\n",
    "    mc: df[col[:-5]].mean()  # strip _mean to get var_human/var_twin\n",
    "    for mc, col in zip(mean_cols, mean_cols)\n",
    "}\n",
    "means_df = pd.DataFrame([means], columns=mean_cols)\n",
    "means_df.to_csv(f\"{study_name}_means_summary.csv\", index=False)\n",
    "print(\"→ means summary written with columns:\", mean_cols)\n",
    "\n",
    "# standard deviations\n",
    "std_cols = [f\"{v}_human_std\" for v in vars_list_human] + [f\"{v}_twin_std\" for v in vars_list_twin]\n",
    "stds = {}\n",
    "# humans\n",
    "for v, col in zip(vars_list_human, std_cols[: len(vars_list_human)]):\n",
    "    stds[col] = df[f\"{v}_human\"].std(ddof=1)\n",
    "# twins\n",
    "for v, col in zip(vars_list_twin, std_cols[len(vars_list_human) :]):\n",
    "    stds[col] = df[f\"{v}_twin\"].std(ddof=1)\n",
    "stds_df = pd.DataFrame([stds], columns=std_cols)\n",
    "stds_df.to_csv(f\"{study_name}_std_summary.csv\", index=False)\n",
    "print(\"→ std‐summary written with columns:\", std_cols)\n",
    "\n",
    "# --- 3) Correlation matrix, rows & columns in the same order ---\n",
    "corr_mat = df[all_cols].corr().loc[all_cols, all_cols]\n",
    "corr_mat.to_csv(f\"{study_name}_correlation_matrix.csv\")\n",
    "print(\"→ correlation matrix written with index/cols:\", all_cols)\n",
    "\n",
    "# --- 4) P-value matrix, rows & columns in the same order ---\n",
    "pval_mat = pd.DataFrame(np.nan, index=all_cols, columns=all_cols)\n",
    "for i in all_cols:\n",
    "    for j in all_cols:\n",
    "        x, y = df[i], df[j]\n",
    "        mask = x.notna() & y.notna()\n",
    "        if mask.sum() > 1:\n",
    "            _, p = pearsonr(x[mask], y[mask])\n",
    "            pval_mat.at[i, j] = p\n",
    "pval_mat = pval_mat.loc[all_cols, all_cols]\n",
    "pval_mat.to_csv(f\"{study_name}_pvalues_matrix.csv\")\n",
    "print(\"→ p-value matrix written with index/cols:\", all_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06111c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE (DAT, SSPT, creativity): [0.06439529 0.01174344 0.17660349]\n",
      "\n",
      "DAT paired t-test for means:\n",
      " t = -12.168, df = 198, p = 0.000\n",
      "SSPT paired t-test for means:\n",
      " t = 1.044, df = 198, p = 0.298\n",
      "creativity paired t-test for means:\n",
      " t = -2.718, df = 198, p = 0.007\n",
      "\n",
      "DAT F-test for variance: F = 7.957, df1 = 198, df2 = 198, p = 0.000\n",
      "SSPT F-test for variance: F = 2.053, df1 = 198, df2 = 198, p = 0.000\n",
      "creativity F-test for variance: F = 1.816, df1 = 198, df2 = 198, p = 0.000\n",
      "\n",
      "DAT correlation: r = 0.068, df = 197, p = 0.343\n",
      "SSPT_standardized correlation: r = 0.105, df = 197, p = 0.139\n",
      "creativity correlation: r = 0.088, df = 197, p = 0.217\n",
      "\n",
      "corr(DAT, SSPT) human vs. twin: z = -0.771, df1 = 196, df2 = 196, p = 0.441\n",
      "corr(DAT, creativity rated by human) human vs. twin: z = -0.279, df1 = 196, df2 = 196, p = 0.780\n",
      "corr(SSPT, creativity rated by human) human vs. twin: z = -1.661, df1 = 196, df2 = 196, p = 0.097\n",
      "corr(DAT, creativity rated by same source) human vs. twin: z = 1.837, df1 = 196, df2 = 196, p = 0.066\n",
      "corr(SSPT, creativity rated by same source) human vs. twin: z = -1.490, df1 = 196, df2 = 196, p = 0.136\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f, norm, pearsonr, ttest_rel\n",
    "\n",
    "# --- 1) extract parallel arrays ---\n",
    "dat_h = df_human[\"DAT_perf\"].to_numpy()\n",
    "dat_t = df_twin[\"DAT_perf\"].to_numpy()\n",
    "sspt_h_standardized = df_human[\"SSPT_standardized\"].to_numpy()\n",
    "sspt_t_standardized = df_twin[\"SSPT_standardized\"].to_numpy()\n",
    "sspt_h = df_human[\"SSPT\"].to_numpy()\n",
    "sspt_t = df_twin[\"SSPT\"].to_numpy()\n",
    "crea_hbyh = df_human[\"creativity_rating_byhuman\"].to_numpy()\n",
    "crea_tbyh = df_twin[\"creativity_rating_byhuman\"].to_numpy()\n",
    "crea_hbyt = df_human[\"creativity_rating_bytwins\"].to_numpy()\n",
    "crea_tbyt = df_twin[\"creativity_rating_bytwins\"].to_numpy()\n",
    "\n",
    "\n",
    "# define common in‐sample mask (non‐missing on all three)\n",
    "mask_dat = ~np.isnan(dat_h) & ~np.isnan(dat_t)\n",
    "mask_sspt = ~np.isnan(sspt_h) & ~np.isnan(sspt_t)\n",
    "mask_crea = ~np.isnan(crea_hbyh) & ~np.isnan(crea_tbyh)\n",
    "indsin = mask_dat & mask_sspt & mask_crea\n",
    "n = indsin.sum()\n",
    "\n",
    "# --- 2) MAPE for each measure ---\n",
    "mape_dat = np.mean(np.abs(dat_h[indsin] - dat_t[indsin]) / dat_h[indsin])\n",
    "mape_sspt = np.mean(np.abs(sspt_h[indsin] - sspt_t[indsin]) / sspt_h[indsin])\n",
    "mape_crea = np.mean(np.abs(crea_hbyh[indsin] - crea_tbyh[indsin]) / crea_hbyh[indsin])\n",
    "mape = np.array([mape_dat, mape_sspt, mape_crea])\n",
    "print(\"MAPE (DAT, SSPT, creativity):\", mape)\n",
    "\n",
    "# --- 3) paired t-tests on means ---\n",
    "n_pairs = indsin.sum()\n",
    "df_pairs = n_pairs - 1\n",
    "\n",
    "print(\"\\nDAT paired t-test for means:\")\n",
    "t_dat, p_dat = ttest_rel(dat_h[indsin], dat_t[indsin])\n",
    "print(f\" t = {t_dat:.3f}, df = {df_pairs}, p = {p_dat:.3f}\")\n",
    "\n",
    "print(\"SSPT paired t-test for means:\")\n",
    "t_sspt, p_sspt = ttest_rel(sspt_h[indsin], sspt_t[indsin])\n",
    "print(f\" t = {t_sspt:.3f}, df = {df_pairs}, p = {p_sspt:.3f}\")\n",
    "\n",
    "print(\"creativity paired t-test for means:\")\n",
    "t_crea, p_crea = ttest_rel(crea_hbyh[indsin], crea_tbyh[indsin])\n",
    "print(f\" t = {t_crea:.3f}, df = {df_pairs}, p = {p_crea:.3f}\")\n",
    "\n",
    "\n",
    "# --- 4) two-sample F-test for variance ---\n",
    "x_dat, y_dat = dat_h[indsin], dat_t[indsin]\n",
    "df1_dat, df2_dat = len(x_dat) - 1, len(y_dat) - 1\n",
    "F_dat, pF_dat = f_test(x_dat, y_dat)\n",
    "print(\n",
    "    f\"\\nDAT F-test for variance: F = {F_dat:.3f}, df1 = {df1_dat}, df2 = {df2_dat}, p = {pF_dat:.3f}\"\n",
    ")\n",
    "\n",
    "x_sspt, y_sspt = sspt_h[indsin], sspt_t[indsin]\n",
    "df1_sspt, df2_sspt = len(x_sspt) - 1, len(y_sspt) - 1\n",
    "F_sspt, pF_sspt = f_test(x_sspt, y_sspt)\n",
    "print(\n",
    "    f\"SSPT F-test for variance: F = {F_sspt:.3f}, df1 = {df1_sspt}, df2 = {df2_sspt}, p = {pF_sspt:.3f}\"\n",
    ")\n",
    "\n",
    "x_crea, y_crea = crea_hbyh[indsin], crea_tbyh[indsin]\n",
    "df1_crea, df2_crea = len(x_crea) - 1, len(y_crea) - 1\n",
    "F_crea, pF_crea = f_test(x_crea, y_crea)\n",
    "print(\n",
    "    f\"creativity F-test for variance: F = {F_crea:.3f}, df1 = {df1_crea}, df2 = {df2_crea}, p = {pF_crea:.3f}\"\n",
    ")\n",
    "\n",
    "\n",
    "# --- 5) correlations ---\n",
    "n_corr = indsin.sum()\n",
    "df_corr = n_corr - 2\n",
    "r_dat, pR_dat = pearsonr(dat_h[indsin], dat_t[indsin])\n",
    "print(f\"\\nDAT correlation: r = {r_dat:.3f}, df = {df_corr}, p = {pR_dat:.3f}\")\n",
    "r_sspt, pR_sspt = pearsonr(sspt_h_standardized[indsin], sspt_t_standardized[indsin])\n",
    "print(f\"SSPT_standardized correlation: r = {r_sspt:.3f}, df = {df_corr}, p = {pR_sspt:.3f}\")\n",
    "r_crea, pR_crea = pearsonr(crea_hbyh[indsin], crea_tbyh[indsin])\n",
    "print(f\"creativity correlation: r = {r_crea:.3f}, df = {df_corr}, p = {pR_crea:.3f}\")\n",
    "\n",
    "# --- 6) z-tests comparing human vs. twin correlations ---\n",
    "\n",
    "\n",
    "def z_test_diff_corr(r1, r2, n1, n2):\n",
    "    z1 = np.arctanh(r1)\n",
    "    z2 = np.arctanh(r2)\n",
    "    se = np.sqrt(1 / (n1 - 3) + 1 / (n2 - 3))\n",
    "    z = (z1 - z2) / se\n",
    "    p = 2 * (1 - norm.cdf(abs(z)))\n",
    "    return z, p\n",
    "\n",
    "\n",
    "df_z1 = n - 3\n",
    "df_z2 = n - 3\n",
    "\n",
    "# DAT vs. SSPT\n",
    "z_dat_sspt, pz_dat_sspt = z_test_diff_corr(\n",
    "    pearsonr(dat_h[indsin], sspt_h_standardized[indsin])[0],\n",
    "    pearsonr(dat_t[indsin], sspt_t_standardized[indsin])[0],\n",
    "    n,\n",
    "    n,\n",
    ")\n",
    "print(\n",
    "    f\"\\ncorr(DAT, SSPT) human vs. twin: \"\n",
    "    f\"z = {z_dat_sspt:.3f}, df1 = {df_z1}, df2 = {df_z2}, p = {pz_dat_sspt:.3f}\"\n",
    ")\n",
    "\n",
    "# DAT vs. creativity (rated by human)\n",
    "z_dat_crea, pz_dat_crea = z_test_diff_corr(\n",
    "    pearsonr(dat_h[indsin], crea_hbyh[indsin])[0],\n",
    "    pearsonr(dat_t[indsin], crea_tbyh[indsin])[0],\n",
    "    n,\n",
    "    n,\n",
    ")\n",
    "print(\n",
    "    f\"corr(DAT, creativity rated by human) human vs. twin: \"\n",
    "    f\"z = {z_dat_crea:.3f}, df1 = {df_z1}, df2 = {df_z2}, p = {pz_dat_crea:.3f}\"\n",
    ")\n",
    "\n",
    "# SSPT vs. creativity (rated by human)\n",
    "z_sspt_crea, pz_sspt_crea = z_test_diff_corr(\n",
    "    pearsonr(sspt_h_standardized[indsin], crea_hbyh[indsin])[0],\n",
    "    pearsonr(sspt_t_standardized[indsin], crea_tbyh[indsin])[0],\n",
    "    n,\n",
    "    n,\n",
    ")\n",
    "print(\n",
    "    f\"corr(SSPT, creativity rated by human) human vs. twin: \"\n",
    "    f\"z = {z_sspt_crea:.3f}, df1 = {df_z1}, df2 = {df_z2}, p = {pz_sspt_crea:.3f}\"\n",
    ")\n",
    "\n",
    "# DAT vs. creativity (rated by same source)\n",
    "z_dat_crea2, pz_dat_crea2 = z_test_diff_corr(\n",
    "    pearsonr(dat_h[indsin], crea_hbyh[indsin])[0],\n",
    "    pearsonr(dat_t[indsin], crea_tbyt[indsin])[0],\n",
    "    n,\n",
    "    n,\n",
    ")\n",
    "print(\n",
    "    f\"corr(DAT, creativity rated by same source) human vs. twin: \"\n",
    "    f\"z = {z_dat_crea2:.3f}, df1 = {df_z1}, df2 = {df_z2}, p = {pz_dat_crea2:.3f}\"\n",
    ")\n",
    "\n",
    "# SSPT vs. creativity (rated by same source)\n",
    "z_sspt_crea2, pz_sspt_crea2 = z_test_diff_corr(\n",
    "    pearsonr(sspt_h_standardized[indsin], crea_hbyh[indsin])[0],\n",
    "    pearsonr(sspt_t_standardized[indsin], crea_tbyt[indsin])[0],\n",
    "    n,\n",
    "    n,\n",
    ")\n",
    "print(\n",
    "    f\"corr(SSPT, creativity rated by same source) human vs. twin: \"\n",
    "    f\"z = {z_sspt_crea2:.3f}, df1 = {df_z1}, df2 = {df_z2}, p = {pz_sspt_crea2:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19475b78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
