{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abd1e8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ot2107\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           study name persona specification variable name  \\\n",
      "0  Targeting fairness       default persona         fair1   \n",
      "\n",
      "   correlation between the responses from humans vs. their twins  CI_lower  \\\n",
      "0                                           0.133345              0.029964   \n",
      "\n",
      "   CI_upper  z-score for correlation between humans vs. their twins  \\\n",
      "0  0.233903                                           2.523903        \n",
      "\n",
      "   accuracy between humans vs. their twins  mean_human  mean_twin  ...  \\\n",
      "0                                 0.794468     6.92437    6.89916  ...   \n",
      "\n",
      "   effect size based on human  effect size based on twin  domain=social?  \\\n",
      "0                   -0.543618                   -1.02321               1   \n",
      "\n",
      "   domain=cognitive?  replicating know human bias?  preference measure?  \\\n",
      "0                  0                             1                    1   \n",
      "\n",
      "   stimuli dependent?  knowledge question?  political question?  sample size  \n",
      "0                   1                    0                    1          357  \n",
      "\n",
      "[1 rows x 26 columns]\n",
      "   TWIN_ID variable_name  value respondent_type          study_name  \\\n",
      "0        2         fair1      9           human  Targeting fairness   \n",
      "1        4         fair1      9           human  Targeting fairness   \n",
      "2        6         fair1      4           human  Targeting fairness   \n",
      "3        9         fair1      7           human  Targeting fairness   \n",
      "4       11         fair1      9           human  Targeting fairness   \n",
      "\n",
      "  specification_name  \n",
      "0    default persona  \n",
      "1    default persona  \n",
      "2    default persona  \n",
      "3    default persona  \n",
      "4    default persona  \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import f, norm, pearsonr, ttest_rel\n",
    "\n",
    "# Load data\n",
    "study_name = \"Targeting fairness\"\n",
    "specification_name = \"default persona\"\n",
    "human_file = f\"{study_name} human data numbers anonymized.csv\"\n",
    "twin_file = f\"{study_name} twins data values anonymized.csv\"\n",
    "df_human = pd.read_csv(human_file, header=0, skiprows=[1, 2])\n",
    "df_twin = pd.read_csv(twin_file, header=0, skiprows=[1, 2])\n",
    "\n",
    "# define relevant columns:\n",
    "# condition variable names:\n",
    "condition_vars = [\"Segment\"]\n",
    "# Check if we have a real condition var\n",
    "if condition_vars and condition_vars[0].strip():\n",
    "    cond = condition_vars[0]\n",
    "    cond_h = f\"{cond}_human\"\n",
    "    cond_t = f\"{cond}_twin\"\n",
    "    cond_exists = True\n",
    "else:\n",
    "    cond_exists = False\n",
    "\n",
    "# #raw responses:\n",
    "# raw_vars = ['fair1']\n",
    "# raw_vars_min = [1]\n",
    "# raw_vars_max = [9]\n",
    "# #raw responses: domain=social?\n",
    "# raw_vars_social=[1]\n",
    "# raw_vars_social_map = dict(zip(raw_vars, raw_vars_social))\n",
    "# #raw responses: domain=cognitive?\n",
    "# raw_vars_cognitive=[0]\n",
    "# raw_vars_cognitive_map = dict(zip(raw_vars, raw_vars_cognitive))\n",
    "# #raw responses: replicating know human bias?\n",
    "# raw_vars_known=[1]\n",
    "# raw_vars_known_map = dict(zip(raw_vars, raw_vars_known))\n",
    "# #raw responses: preference measure?\n",
    "# raw_vars_pref=[1]\n",
    "# raw_vars_pref_map = dict(zip(raw_vars, raw_vars_pref))\n",
    "# #raw responses: stimuli dependent?\n",
    "# raw_vars_stim=[1]\n",
    "# raw_vars_stim_map = dict(zip(raw_vars, raw_vars_stim))\n",
    "\n",
    "# DVs:\n",
    "DV_vars = [\"fair1\"]\n",
    "DV_vars_min = [1]\n",
    "DV_vars_max = [9]\n",
    "# DVs: domain=social?\n",
    "DV_vars_social = [1]\n",
    "DV_vars_social_map = dict(zip(DV_vars, DV_vars_social))\n",
    "# DVs: domain=cognitive?\n",
    "DV_vars_cognitive = [0]\n",
    "DV_vars_cognitive_map = dict(zip(DV_vars, DV_vars_cognitive))\n",
    "# DVs: replicating know human bias?\n",
    "DV_vars_known = [1]\n",
    "DV_vars_known_map = dict(zip(DV_vars, DV_vars_known))\n",
    "# DVs: preference measure?\n",
    "DV_vars_pref = [1]\n",
    "DV_vars_pref_map = dict(zip(DV_vars, DV_vars_pref))\n",
    "# DVs: stimuli dependent?\n",
    "DV_vars_stim = [1]\n",
    "DV_vars_stim_map = dict(zip(DV_vars, DV_vars_stim))\n",
    "# DVs: knowledge question?\n",
    "DV_vars_know = [0]\n",
    "DV_vars_know_map = dict(zip(DV_vars, DV_vars_know))\n",
    "# DVs: political question?\n",
    "DV_vars_politics = [1]\n",
    "DV_vars_politics_map = dict(zip(DV_vars, DV_vars_politics))\n",
    "\n",
    "# merging key\n",
    "merge_key = [\"TWIN_ID\"]\n",
    "\n",
    "# Merge on TWIN_ID\n",
    "df = pd.merge(df_human, df_twin, on=merge_key, suffixes=(\"_human\", \"_twin\"))\n",
    "\n",
    "# Fix dtypes\n",
    "# for var in raw_vars + DV_vars:\n",
    "for var in DV_vars:\n",
    "    df[f\"{var}_human\"] = pd.to_numeric(df[f\"{var}_human\"], errors=\"coerce\")\n",
    "    df[f\"{var}_twin\"] = pd.to_numeric(df[f\"{var}_twin\"], errors=\"coerce\")\n",
    "\n",
    "# build min/max maps from both raw_vars and DV_vars\n",
    "min_map = {v: mn for v, mn in zip(DV_vars, DV_vars_min)}\n",
    "# min_map = {v: mn for v, mn in zip(raw_vars,      raw_vars_min)}\n",
    "# min_map.update({v: mn for v, mn in zip(DV_vars,   DV_vars_min)})\n",
    "\n",
    "max_map = {v: mx for v, mx in zip(DV_vars, DV_vars_max)}\n",
    "# max_map = {v: mx for v, mx in zip(raw_vars,      raw_vars_max)}\n",
    "# max_map.update({v: mx for v, mx in zip(DV_vars,   DV_vars_max)})\n",
    "\n",
    "# now add _min and _max columns for every variable in the union\n",
    "for var in min_map:\n",
    "    df[f\"{var}_min\"] = min_map[var]\n",
    "    df[f\"{var}_max\"] = max_map[var]\n",
    "\n",
    "# Compute results\n",
    "results = []\n",
    "# for var in raw_vars:\n",
    "#     col_h = f\"{var}_human\"\n",
    "#     col_t = f\"{var}_twin\"\n",
    "#     min_col = f\"{var}_min\"\n",
    "#     max_col = f\"{var}_max\"\n",
    "#     if cond_exists:\n",
    "#         cols = [col_h, col_t, cond_h, cond_t,min_col,max_col]\n",
    "#     else:\n",
    "#         cols = [col_h, col_t,min_col,max_col]\n",
    "#     pair = (\n",
    "#     df[cols]\n",
    "#       .dropna(subset=[col_h, col_t])\n",
    "#     )\n",
    "#     min_val = pair[min_col].iloc[0]\n",
    "#     max_val = pair[max_col].iloc[0]\n",
    "#     n    = len(pair)\n",
    "#     if n >= 4:\n",
    "#         r, _    = pearsonr(pair[col_h], pair[col_t])\n",
    "#         z_f     = np.arctanh(r)\n",
    "#         se      = 1 / np.sqrt(n - 3)\n",
    "#         z_crit  = norm.ppf(0.975)\n",
    "#         lo_z, hi_z = z_f - z_crit*se, z_f + z_crit*se\n",
    "#         lo_r, hi_r = np.tanh(lo_z), np.tanh(hi_z)\n",
    "#         z_score    = z_f / se\n",
    "#         # Accuracy = mean absolute diff / range\n",
    "#         if pd.isna(min_val) or pd.isna(max_val) or max_val == min_val:\n",
    "#             accuracy = np.nan\n",
    "#         else:\n",
    "#             # compute mean absolute difference\n",
    "#             abs_diff      = np.abs(pair[col_h] - pair[col_t])\n",
    "#             mean_abs_diff = abs_diff.mean()\n",
    "#             accuracy      = 1 - mean_abs_diff / (max_val - min_val)\n",
    "\n",
    "#         mean_h = pair[col_h].mean()\n",
    "#         mean_t = pair[col_t].mean()\n",
    "\n",
    "#         # Paired t‐test\n",
    "#         t_stat, p_val = ttest_rel(pair[col_h], pair[col_t])\n",
    "\n",
    "#         std_h = pair[col_h].std(ddof=1)\n",
    "#         std_t = pair[col_t].std(ddof=1)\n",
    "\n",
    "#          # F‐test for equal variances\n",
    "#         df1 = df2 = n - 1\n",
    "#         f_stat = (std_h**2 / std_t**2) if std_t>0 else np.nan\n",
    "\n",
    "#         # two‐tailed p‐value:\n",
    "#         if not np.isnan(f_stat):\n",
    "#             p_f = 2 * min(f.cdf(f_stat, df1, df2),\n",
    "#                           1 - f.cdf(f_stat, df1, df2))\n",
    "#         else:\n",
    "#             p_f = np.nan\n",
    "\n",
    "#         # Effect sizes (Cohen's d) across conditions\n",
    "#         #    For humans:\n",
    "#         if cond_exists and len(pair)>3:\n",
    "#             levels_h = pair[cond_h].unique()\n",
    "#             if len(levels_h) == 2:\n",
    "#                 g1 = pair.loc[pair[cond_h]==levels_h[0], col_h]\n",
    "#                 g2 = pair.loc[pair[cond_h]==levels_h[1], col_h]\n",
    "#                 n1, n2 = len(g1), len(g2)\n",
    "#                 # pooled sd\n",
    "#                 s_pool = np.sqrt(((n1-1)*g1.var(ddof=1)+(n2-1)*g2.var(ddof=1)) / (n1+n2-2))\n",
    "#                 d_human = (g1.mean() - g2.mean()) / s_pool if s_pool>0 else np.nan\n",
    "#             else:\n",
    "#                 d_human = np.nan\n",
    "#         else:\n",
    "#             d_human = np.nan\n",
    "\n",
    "#         #    For twins:\n",
    "#         if cond_exists and len(pair)>3:\n",
    "#             levels_t = pair[cond_t].unique()\n",
    "#             if cond_exists and len(levels_t) == 2:\n",
    "#                 g1 = pair.loc[pair[cond_t]==levels_t[0], col_t]\n",
    "#                 g2 = pair.loc[pair[cond_t]==levels_t[1], col_t]\n",
    "#                 n1, n2 = len(g1), len(g2)\n",
    "#                 s_pool = np.sqrt(((n1-1)*g1.var(ddof=1)+(n2-1)*g2.var(ddof=1)) / (n1+n2-2))\n",
    "#                 d_twin = (g1.mean() - g2.mean()) / s_pool if s_pool>0 else np.nan\n",
    "#             else:\n",
    "#                 d_twin = np.nan\n",
    "#         else:\n",
    "#             d_twin = np.nan\n",
    "#     else:\n",
    "#         r = lo_r = hi_r = z_score = accuracy = mean_h = mean_t = t_stat = p_val = std_h = std_t = f_stat = p_f = np.nan\n",
    "#         d_human = d_twin = np.nan\n",
    "\n",
    "\n",
    "#     results.append({\n",
    "#         'study name': study_name,\n",
    "#         'variable name': var,\n",
    "#         'variable type (raw response/DV)':     'raw',\n",
    "#         'correlation between the responses from humans vs. their twins':        r,\n",
    "#         'CI_lower': lo_r,\n",
    "#         'CI_upper': hi_r,\n",
    "#         'z-score for correlation between humans vs. their twins':  z_score,\n",
    "#         'accuracy between humans vs. their twins': accuracy,\n",
    "#         'mean_human': mean_h,\n",
    "#         'mean_twin': mean_t,\n",
    "#         'paired t-test t-stat': t_stat,\n",
    "#         'paired t-test p-value': p_val,\n",
    "#         'std_human': std_h,\n",
    "#         'std_twin': std_t,\n",
    "#         'variance test F-stat': f_stat,\n",
    "#         'variance test p-value': p_f,\n",
    "#         'effect size based on human': d_human,\n",
    "#         'effect size based on twin': d_twin,\n",
    "#         'domain=social?':raw_vars_social_map.get(var, np.nan),\n",
    "#         'domain=cognitive?':raw_vars_cognitive_map.get(var, np.nan),\n",
    "#         'replicating know human bias?':raw_vars_known_map.get(var, np.nan),\n",
    "#         'preference measure?':raw_vars_pref_map.get(var, np.nan),\n",
    "#         'stimuli dependent?':raw_vars_stim_map.get(var, np.nan),\n",
    "#         'sample size':        n\n",
    "#     })\n",
    "\n",
    "for var in DV_vars:\n",
    "    col_h = f\"{var}_human\"\n",
    "    col_t = f\"{var}_twin\"\n",
    "    min_col = f\"{var}_min\"\n",
    "    max_col = f\"{var}_max\"\n",
    "    if cond_exists:\n",
    "        cols = [col_h, col_t, cond_h, cond_t, min_col, max_col]\n",
    "    else:\n",
    "        cols = [col_h, col_t, min_col, max_col]\n",
    "    pair = df[cols].dropna(subset=[col_h, col_t])\n",
    "    min_val = pair[min_col].iloc[0]\n",
    "    max_val = pair[max_col].iloc[0]\n",
    "    n = len(pair)\n",
    "    if n >= 4:\n",
    "        r, _ = pearsonr(pair[col_h], pair[col_t])\n",
    "        z_f = np.arctanh(r)\n",
    "        se = 1 / np.sqrt(n - 3)\n",
    "        z_crit = norm.ppf(0.975)\n",
    "        lo_z, hi_z = z_f - z_crit * se, z_f + z_crit * se\n",
    "        lo_r, hi_r = np.tanh(lo_z), np.tanh(hi_z)\n",
    "        z_score = z_f / se\n",
    "        # Accuracy = mean absolute diff / range\n",
    "        if pd.isna(min_val) or pd.isna(max_val) or max_val == min_val:\n",
    "            accuracy = np.nan\n",
    "        else:\n",
    "            # compute mean absolute difference\n",
    "            abs_diff = np.abs(pair[col_h] - pair[col_t])\n",
    "            mean_abs_diff = abs_diff.mean()\n",
    "            accuracy = 1 - mean_abs_diff / (max_val - min_val)\n",
    "\n",
    "        mean_h = pair[col_h].mean()\n",
    "        mean_t = pair[col_t].mean()\n",
    "\n",
    "        # Paired t‐test\n",
    "        t_stat, p_val = ttest_rel(pair[col_h], pair[col_t])\n",
    "\n",
    "        std_h = pair[col_h].std(ddof=1)\n",
    "        std_t = pair[col_t].std(ddof=1)\n",
    "\n",
    "        # F‐test for equal variances\n",
    "        df1 = df2 = n - 1\n",
    "        f_stat = (std_h**2 / std_t**2) if std_t > 0 else np.nan\n",
    "        # two‐tailed p‐value:\n",
    "        if not np.isnan(f_stat):\n",
    "            p_f = 2 * min(f.cdf(f_stat, df1, df2), 1 - f.cdf(f_stat, df1, df2))\n",
    "        else:\n",
    "            p_f = np.nan\n",
    "\n",
    "        # Effect sizes (Cohen's d) across conditions\n",
    "        #    For humans:\n",
    "        if cond_exists and len(pair) > 3:\n",
    "            levels_h = pair[cond_h].unique()\n",
    "            if len(levels_h) == 2:\n",
    "                g1 = pair.loc[pair[cond_h] == levels_h[0], col_h]\n",
    "                g2 = pair.loc[pair[cond_h] == levels_h[1], col_h]\n",
    "                n1, n2 = len(g1), len(g2)\n",
    "                # pooled sd\n",
    "                s_pool = np.sqrt(\n",
    "                    ((n1 - 1) * g1.var(ddof=1) + (n2 - 1) * g2.var(ddof=1)) / (n1 + n2 - 2)\n",
    "                )\n",
    "                d_human = (g1.mean() - g2.mean()) / s_pool if s_pool > 0 else np.nan\n",
    "            else:\n",
    "                d_human = np.nan\n",
    "        else:\n",
    "            d_human = np.nan\n",
    "\n",
    "        #    For twins:\n",
    "        if cond_exists and len(pair) > 3:\n",
    "            levels_t = pair[cond_t].unique()\n",
    "            if cond_exists and len(levels_t) == 2:\n",
    "                g1 = pair.loc[pair[cond_t] == levels_t[0], col_t]\n",
    "                g2 = pair.loc[pair[cond_t] == levels_t[1], col_t]\n",
    "                n1, n2 = len(g1), len(g2)\n",
    "                s_pool = np.sqrt(\n",
    "                    ((n1 - 1) * g1.var(ddof=1) + (n2 - 1) * g2.var(ddof=1)) / (n1 + n2 - 2)\n",
    "                )\n",
    "                d_twin = (g1.mean() - g2.mean()) / s_pool if s_pool > 0 else np.nan\n",
    "            else:\n",
    "                d_twin = np.nan\n",
    "        else:\n",
    "            d_twin = np.nan\n",
    "    else:\n",
    "        r = lo_r = hi_r = z_score = accuracy = mean_h = mean_t = t_stat = p_val = std_h = std_t = (\n",
    "            f_stat\n",
    "        ) = p_f = np.nan\n",
    "        d_human = d_twin = np.nan\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"study name\": study_name,\n",
    "            \"persona specification\": specification_name,\n",
    "            \"variable name\": var,\n",
    "            #        'variable type (raw response/DV)':     'DV',\n",
    "            \"correlation between the responses from humans vs. their twins\": r,\n",
    "            \"CI_lower\": lo_r,\n",
    "            \"CI_upper\": hi_r,\n",
    "            \"z-score for correlation between humans vs. their twins\": z_score,\n",
    "            \"accuracy between humans vs. their twins\": accuracy,\n",
    "            \"mean_human\": mean_h,\n",
    "            \"mean_twin\": mean_t,\n",
    "            \"paired t-test t-stat\": t_stat,\n",
    "            \"paired t-test p-value\": p_val,\n",
    "            \"std_human\": std_h,\n",
    "            \"std_twin\": std_t,\n",
    "            \"variance test F-stat\": f_stat,\n",
    "            \"variance test p-value\": p_f,\n",
    "            \"effect size based on human\": d_human,\n",
    "            \"effect size based on twin\": d_twin,\n",
    "            \"domain=social?\": DV_vars_social_map.get(var, np.nan),\n",
    "            \"domain=cognitive?\": DV_vars_cognitive_map.get(var, np.nan),\n",
    "            \"replicating know human bias?\": DV_vars_known_map.get(var, np.nan),\n",
    "            \"preference measure?\": DV_vars_pref_map.get(var, np.nan),\n",
    "            \"stimuli dependent?\": DV_vars_stim_map.get(var, np.nan),\n",
    "            \"knowledge question?\": DV_vars_know_map.get(var, np.nan),\n",
    "            \"political question?\": DV_vars_politics_map.get(var, np.nan),\n",
    "            \"sample size\": n,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# results DataFrame\n",
    "corr_df = pd.DataFrame(results)\n",
    "print(corr_df)\n",
    "\n",
    "# save output as csv - unit of observation is comparison between humans and twins:\n",
    "out_file = f\"{study_name} {specification_name} meta analysis.csv\"\n",
    "corr_df.to_csv(out_file, index=False)\n",
    "\n",
    "\n",
    "#####participant-level data:\n",
    "def make_long(df, respondent_type):\n",
    "    # pick off TWIN_ID + the DVs, then melt\n",
    "    long = df[[\"TWIN_ID\"] + DV_vars].melt(\n",
    "        id_vars=\"TWIN_ID\", value_vars=DV_vars, var_name=\"variable_name\", value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    long[\"respondent_type\"] = respondent_type\n",
    "    long[\"study_name\"] = study_name\n",
    "    long[\"specification_name\"] = specification_name\n",
    "    return long\n",
    "\n",
    "\n",
    "# build the two halves\n",
    "long_h = make_long(df_human, \"human\")\n",
    "long_t = make_long(df_twin, \"twin\")\n",
    "\n",
    "# stack them\n",
    "df_long = pd.concat([long_h, long_t], ignore_index=True)\n",
    "\n",
    "print(df_long.head())\n",
    "# save output as csv - unit of observation is TWIN_ID:\n",
    "out_file = f\"{study_name} {specification_name} meta analysis individual level.csv\"\n",
    "df_long.to_csv(out_file, index=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4396099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
