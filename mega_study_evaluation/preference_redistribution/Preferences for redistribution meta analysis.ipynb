{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d50c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ot2107\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human-sample removals due to response time (35 IDs):\n",
      " {1025, 1291, 13, 21, 537, 410, 924, 1308, 542, 799, 928, 1182, 1184, 1567, 1954, 806, 1577, 44, 47, 1337, 1085, 1981, 67, 1347, 72, 336, 998, 1383, 618, 880, 1013, 246, 1016, 1530, 1915}\n",
      "Twin-sample removals due to response time (35 IDs):\n",
      " {1025, 1291, 13, 21, 537, 410, 924, 1308, 542, 799, 928, 1182, 1184, 1567, 1954, 806, 1577, 44, 47, 1337, 1085, 1981, 67, 1347, 72, 336, 998, 1383, 618, 880, 1013, 246, 1016, 1530, 1915}\n",
      "Sets equal?  True\n",
      "In human only: set()\n",
      "In twin only:  set()\n",
      "After filtering:\n",
      " df_human: (1198, 35) → (1163, 35)\n",
      " df_twin:  (1198, 35) → (1163, 35)\n",
      "Failed attention in human (n=0): set()\n",
      "Failed attention in twin  (n=0): set()\n",
      "\n",
      "After attention‐check filtering:\n",
      " df_human: (1163, 35) → (1163, 35)\n",
      " df_twin:  (1163, 35) → (1163, 35)\n",
      "\n",
      "==== Human sample ====\n",
      "\n",
      "– GOVT_RESPONSIBILITY vs Redistribution 1 –\n",
      "Redistribution 1                                    1.0  2.0  3.0  4.0  5.0  \\\n",
      "GOVT_RESPONSIBILITY                                                           \n",
      "1 - I strongly agree the government should impr...    0    0    0    0  369   \n",
      "2                                                     0    0    0  232    0   \n",
      "3 - I agree with both answers                         0    0  313    0    0   \n",
      "4                                                     0  142    0    0    0   \n",
      "5 - I strongly agree that people should take ca...   97    0    0    0    0   \n",
      "Don't know                                            0    0    0    0    0   \n",
      "\n",
      "Redistribution 1                                    NaN  \n",
      "GOVT_RESPONSIBILITY                                      \n",
      "1 - I strongly agree the government should impr...    0  \n",
      "2                                                     0  \n",
      "3 - I agree with both answers                         0  \n",
      "4                                                     0  \n",
      "5 - I strongly agree that people should take ca...    0  \n",
      "Don't know                                           10  \n",
      "\n",
      "– HLTHTAX vs Redistribution 2 –\n",
      "Redistribution 2               1.0  2.0  3.0  4.0  5.0  NaN\n",
      "HLTHTAX                                                    \n",
      "Don’t know/Can't choose          0    0    0    0    0   19\n",
      "Fairly unwilling                 0  160    0    0    0    0\n",
      "Fairly willing                   0    0    0  407    0    0\n",
      "Neither willing nor unwilling    0    0  168    0    0    0\n",
      "Very unwilling                 190    0    0    0    0    0\n",
      "Very willing                     0    0    0    0  219    0\n",
      "\n",
      "– FAIR vs Fairness –\n",
      "Fairness                     1.0  2.0  3.0  NaN\n",
      "FAIR                                           \n",
      "Don't know                     0    0    0   12\n",
      "It depends                     0  515    0    0\n",
      "Would take advantage of you    0    0  293    0\n",
      "Would try to be fair         343    0    0    0\n",
      "\n",
      "– GETAHEAD vs Work vs Luck –\n",
      "Work vs Luck                                   1.0  2.0  3.0  NaN\n",
      "GETAHEAD                                                         \n",
      "Don't know                                       0    0    0    5\n",
      "Hard work and luck are equally important         0  572    0    0\n",
      "Hard work most important                       378    0    0    0\n",
      "Luck or help from other people most important    0    0  208    0\n",
      "\n",
      "– FAEDUC vs Father education –\n",
      "Father education                       10   12   13  14   16   18\n",
      "FAEDUC                                                           \n",
      "Associate's degree                      0    0    0  93    0    0\n",
      "College graduate / some postgraduate    0    0    0   0  273    0\n",
      "High school graduate                    0  375    0   0    0    0\n",
      "Less than high school                 148    0    0   0    0    0\n",
      "Postgraduate degree                     0    0    0   0    0  135\n",
      "Some college, no degree                 0    0  139   0    0    0\n",
      "\n",
      "– TRUST_GSS vs Trust –\n",
      "Trust                 1.0  2.0  3.0  NaN\n",
      "TRUST_GSS                               \n",
      "Can trust               0    0  195    0\n",
      "Can't be too careful  513    0    0    0\n",
      "Depends                 0  454    0    0\n",
      "Don’t know              0    0    0    1\n",
      "\n",
      "\n",
      "==== Twin sample ====\n",
      "\n",
      "– GOVT_RESPONSIBILITY vs Redistribution 1 –\n",
      "Redistribution 1                                      1   2    3   4    5\n",
      "GOVT_RESPONSIBILITY                                                      \n",
      "1 - I strongly agree the government should impr...    0   0    0   0  545\n",
      "2                                                     0   0    0  41    0\n",
      "3 - I agree with both answers                         0   0  224   0    0\n",
      "4                                                     0  83    0   0    0\n",
      "5 - I strongly agree that people should take ca...  270   0    0   0    0\n",
      "\n",
      "– HLTHTAX vs Redistribution 2 –\n",
      "Redistribution 2                 1   2   3    4    5\n",
      "HLTHTAX                                             \n",
      "Fairly unwilling                 0  91   0    0    0\n",
      "Fairly willing                   0   0   0  314    0\n",
      "Neither willing nor unwilling    0   0  77    0    0\n",
      "Very unwilling                 219   0   0    0    0\n",
      "Very willing                     0   0   0    0  462\n",
      "\n",
      "– FAIR vs Fairness –\n",
      "Fairness                       1    2    3\n",
      "FAIR                                      \n",
      "It depends                     0  146    0\n",
      "Would take advantage of you    0    0  338\n",
      "Would try to be fair         679    0    0\n",
      "\n",
      "– GETAHEAD vs Work vs Luck –\n",
      "Work vs Luck                                     1    2   3\n",
      "GETAHEAD                                                   \n",
      "Hard work and luck are equally important         0  792   0\n",
      "Hard work most important                       361    0   0\n",
      "Luck or help from other people most important    0    0  10\n",
      "\n",
      "– FAEDUC vs Father education –\n",
      "Father education                      10    12  13  16  18\n",
      "FAEDUC                                                    \n",
      "College graduate / some postgraduate   0     0   0  31   0\n",
      "High school graduate                   0  1114   0   0   0\n",
      "Less than high school                 15     0   0   0   0\n",
      "Postgraduate degree                    0     0   0   0   1\n",
      "Some college, no degree                0     0   2   0   0\n",
      "\n",
      "– TRUST_GSS vs Trust –\n",
      "Trust                   1    2    3\n",
      "TRUST_GSS                          \n",
      "Can trust               0    0  650\n",
      "Can't be too careful  399    0    0\n",
      "Depends                 0  114    0\n",
      "\n",
      "                       study name persona specification     variable name  \\\n",
      "0  Preferences for redistribution       default persona  Redistribution 1   \n",
      "1  Preferences for redistribution       default persona  Redistribution 2   \n",
      "2  Preferences for redistribution       default persona          Fairness   \n",
      "3  Preferences for redistribution       default persona      Work vs Luck   \n",
      "4  Preferences for redistribution       default persona  Father education   \n",
      "5  Preferences for redistribution       default persona             Trust   \n",
      "\n",
      "   correlation between the responses from humans vs. their twins  CI_lower  \\\n",
      "0                                           0.620508              0.583686   \n",
      "1                                           0.613883              0.576433   \n",
      "2                                           0.298406              0.244846   \n",
      "3                                           0.346408              0.294682   \n",
      "4                                           0.125703              0.068716   \n",
      "5                                           0.295795              0.242410   \n",
      "\n",
      "   CI_upper  z-score for correlation between humans vs. their twins  \\\n",
      "0  0.654784                                          24.614139        \n",
      "1  0.648759                                          24.156102        \n",
      "2  0.350151                                          10.427868        \n",
      "3  0.396111                                          12.280804        \n",
      "4  0.181871                                           4.304040        \n",
      "5  0.347393                                          10.380206        \n",
      "\n",
      "   accuracy between humans vs. their twins  mean_human  mean_twin  ...  \\\n",
      "0                                 0.779705    3.549870   3.438855  ...   \n",
      "1                                 0.778191    3.266608   3.611888  ...   \n",
      "2                                 0.640747    1.956560   1.705474  ...   \n",
      "3                                 0.769862    1.853195   1.696891  ...   \n",
      "4                                 0.733126   13.660361  12.087704  ...   \n",
      "5                                 0.592943    1.726334   2.215146  ...   \n",
      "\n",
      "   effect size based on human  effect size based on twin  domain=social?  \\\n",
      "0                         NaN                        NaN               1   \n",
      "1                         NaN                        NaN               1   \n",
      "2                         NaN                        NaN               1   \n",
      "3                         NaN                        NaN               1   \n",
      "4                         NaN                        NaN               0   \n",
      "5                         NaN                        NaN               1   \n",
      "\n",
      "   domain=cognitive?  replicating know human bias?  preference measure?  \\\n",
      "0                  0                             0                    1   \n",
      "1                  0                             0                    1   \n",
      "2                  0                             0                    0   \n",
      "3                  0                             0                    0   \n",
      "4                  0                             0                    0   \n",
      "5                  0                             0                    0   \n",
      "\n",
      "   stimuli dependent?  knowledge question?  political question?  sample size  \n",
      "0                   0                    0                    1         1153  \n",
      "1                   0                    0                    1         1144  \n",
      "2                   0                    0                    0         1151  \n",
      "3                   0                    0                    0         1158  \n",
      "4                   0                    0                    0         1163  \n",
      "5                   0                    0                    0         1162  \n",
      "\n",
      "[6 rows x 26 columns]\n",
      "   TWIN_ID     variable_name  value respondent_type  \\\n",
      "0        1  Redistribution 1    4.0           human   \n",
      "1        2  Redistribution 1    5.0           human   \n",
      "2        3  Redistribution 1    3.0           human   \n",
      "3        4  Redistribution 1    5.0           human   \n",
      "4        5  Redistribution 1    3.0           human   \n",
      "\n",
      "                       study_name specification_name  \n",
      "0  Preferences for redistribution    default persona  \n",
      "1  Preferences for redistribution    default persona  \n",
      "2  Preferences for redistribution    default persona  \n",
      "3  Preferences for redistribution    default persona  \n",
      "4  Preferences for redistribution    default persona  \n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import f, norm, pearsonr, ttest_rel\n",
    "\n",
    "# Load data\n",
    "study_name = \"Preferences for redistribution\"\n",
    "specification_name = \"default persona\"\n",
    "human_file = f\"{study_name} human data labels anonymized.csv\"\n",
    "twin_file = f\"{study_name} twins data labels anonymized.csv\"\n",
    "df_human = pd.read_csv(human_file, header=0, skiprows=[1, 2])\n",
    "df_twin = pd.read_csv(twin_file, header=0, skiprows=[1, 2])\n",
    "\n",
    "# remove observations if their completion time was less than 50% of the median survey duration.\n",
    "# Compute 50%-of-median thresholds\n",
    "median_human = df_human[\"Duration (in seconds)\"].median()\n",
    "threshold_human = 0.5 * median_human\n",
    "median_twin = df_twin[\"Duration (in seconds)\"].median()\n",
    "threshold_twin = 0.5 * median_twin\n",
    "# Identify which TWIN_IDs would be removed\n",
    "removed_human = df_human.loc[df_human[\"Duration (in seconds)\"] < threshold_human, \"TWIN_ID\"]\n",
    "removed_twin = df_twin.loc[df_twin[\"Duration (in seconds)\"] < threshold_twin, \"TWIN_ID\"]\n",
    "set_human = set(removed_human)\n",
    "set_twin = set(removed_twin)\n",
    "# Compare the two sets\n",
    "print(f\"Human-sample removals due to response time ({len(set_human)} IDs):\\n\", set_human)\n",
    "print(f\"Twin-sample removals due to response time ({len(set_twin)} IDs):\\n\", set_twin)\n",
    "print(\"Sets equal? \", set_human == set_twin)\n",
    "print(\"In human only:\", set_human - set_twin)\n",
    "print(\"In twin only: \", set_twin - set_human)\n",
    "\n",
    "# Actually filter out those rows\n",
    "df_human_filtered = df_human[df_human[\"Duration (in seconds)\"] >= threshold_human].copy()\n",
    "df_twin_filtered = df_twin[df_twin[\"Duration (in seconds)\"] >= threshold_twin].copy()\n",
    "# inspect sizes\n",
    "print(\"After filtering:\")\n",
    "print(\" df_human:\", df_human.shape, \"→\", df_human_filtered.shape)\n",
    "print(\" df_twin: \", df_twin.shape, \"→\", df_twin_filtered.shape)\n",
    "\n",
    "# remove those failing the attention check question in the survey. Specifically, this questions asks: \"To ensure you're paying attention, please select “Don’t know” as your answer to this question:\n",
    "# Identify who failed in df_human and df_twin\n",
    "fail_human = df_human_filtered.loc[df_human_filtered[\"ATTENTION_CHECK\"] != \"Don’t know\", \"TWIN_ID\"]\n",
    "fail_twin = df_twin_filtered.loc[df_twin_filtered[\"ATTENTION_CHECK\"] != \"Don’t know\", \"TWIN_ID\"]\n",
    "# Print the sets of failing IDs\n",
    "set_fail_human = set(fail_human)\n",
    "set_fail_twin = set(fail_twin)\n",
    "print(\"Failed attention in human (n={}):\".format(len(set_fail_human)), set_fail_human)\n",
    "print(\"Failed attention in twin  (n={}):\".format(len(set_fail_twin)), set_fail_twin)\n",
    "# Remove everyone who failed in the *human* sample, from both dfs\n",
    "ids_to_remove = set_fail_human\n",
    "df_human_clean = df_human_filtered.loc[~df_human_filtered[\"TWIN_ID\"].isin(ids_to_remove)].copy()\n",
    "\n",
    "df_twin_clean = df_twin_filtered.loc[~df_twin_filtered[\"TWIN_ID\"].isin(ids_to_remove)].copy()\n",
    "# Quick sanity check\n",
    "print(\"\\nAfter attention‐check filtering:\")\n",
    "print(\" df_human: {} → {}\".format(df_human_filtered.shape, df_human_clean.shape))\n",
    "print(\" df_twin:  {} → {}\".format(df_twin_filtered.shape, df_twin_clean.shape))\n",
    "\n",
    "\n",
    "df_human = df_human_clean\n",
    "df_twin = df_twin_clean\n",
    "\n",
    "\n",
    "# add new columns with relevant variables coded\n",
    "\n",
    "redistribution1_map = {\n",
    "    \"1 - I strongly agree the government should improve living standards\": 5,\n",
    "    \"2\": 4,\n",
    "    \"3 - I agree with both answers\": 3,\n",
    "    \"4\": 2,\n",
    "    \"5 - I strongly agree that people should take care of themselves\": 1,\n",
    "    # any other value (e.g. \"Don't know\") will become NaN\n",
    "}\n",
    "\n",
    "redistribution2_map = {\n",
    "    \"Very willing\": 5,\n",
    "    \"Fairly willing\": 4,\n",
    "    \"Neither willing nor unwilling\": 3,\n",
    "    \"Fairly unwilling\": 2,\n",
    "    \"Very unwilling\": 1,\n",
    "    # e.g. \"Donâ€™t know/Can't choose\" → NaN\n",
    "}\n",
    "\n",
    "fairness_map = {\n",
    "    \"Would take advantage of you\": 3,\n",
    "    \"It depends\": 2,\n",
    "    \"Would try to be fair\": 1,\n",
    "    # \"Don’t know\" → NaN\n",
    "}\n",
    "\n",
    "workluck_map = {\n",
    "    \"Hard work most important\": 1,\n",
    "    \"Hard work and luck are equally important\": 2,\n",
    "    \"Luck or help from other people most important\": 3,\n",
    "    # \"Don't know\" → NaN\n",
    "}\n",
    "\n",
    "father_educ_map = {\n",
    "    \"Less than high school\": 10,\n",
    "    \"High school graduate\": 12,\n",
    "    \"Some college, no degree\": 13,\n",
    "    \"Associate's degree\": 14,\n",
    "    \"College graduate / some postgraduate\": 16,\n",
    "    \"Postgraduate degree\": 18,\n",
    "}\n",
    "\n",
    "trust_map = {\n",
    "    \"Can trust\": 3,\n",
    "    \"Depends\": 2,\n",
    "    \"Can't be too careful\": 1,\n",
    "    # \"Don’t know\" → NaN\n",
    "}\n",
    "\n",
    "\n",
    "for df in (df_human, df_twin):\n",
    "    df[\"Redistribution 1\"] = df[\"GOVT_RESPONSIBILITY\"].map(redistribution1_map)\n",
    "    df[\"Redistribution 2\"] = df[\"HLTHTAX\"].map(redistribution2_map)\n",
    "    df[\"Fairness\"] = df[\"FAIR\"].map(fairness_map)\n",
    "    df[\"Work vs Luck\"] = df[\"GETAHEAD\"].map(workluck_map)\n",
    "    df[\"Father education\"] = df[\"FAEDUC\"].map(father_educ_map)\n",
    "    df[\"Trust\"] = df[\"TRUST_GSS\"].map(trust_map)\n",
    "\n",
    "# check results:\n",
    "pairs = [\n",
    "    (\"GOVT_RESPONSIBILITY\", \"Redistribution 1\"),\n",
    "    (\"HLTHTAX\", \"Redistribution 2\"),\n",
    "    (\"FAIR\", \"Fairness\"),\n",
    "    (\"GETAHEAD\", \"Work vs Luck\"),\n",
    "    (\"FAEDUC\", \"Father education\"),\n",
    "    (\"TRUST_GSS\", \"Trust\"),\n",
    "]\n",
    "\n",
    "for df_name, df in [(\"Human\", df_human), (\"Twin\", df_twin)]:\n",
    "    print(f\"\\n==== {df_name} sample ====\\n\")\n",
    "    for orig, new in pairs:\n",
    "        print(f\"– {orig} vs {new} –\")\n",
    "        ct = pd.crosstab(df[orig], df[new], dropna=False)\n",
    "        print(ct)\n",
    "        print()\n",
    "\n",
    "\n",
    "# define relevant columns:\n",
    "# condition variable names:\n",
    "condition_vars = [\"\"]\n",
    "# Check if we have a real condition var\n",
    "if condition_vars and condition_vars[0].strip():\n",
    "    cond = condition_vars[0]\n",
    "    cond_h = f\"{cond}_human\"\n",
    "    cond_t = f\"{cond}_twin\"\n",
    "    cond_exists = True\n",
    "else:\n",
    "    cond_exists = False\n",
    "\n",
    "# #raw responses:\n",
    "# raw_vars = ['Redistribution 1','Redistribution 2','Fairness','Work vs Luck','Father education','Trust']\n",
    "# raw_vars_min = [1,1,1,1,10,1]\n",
    "# raw_vars_max = [5,5,3,3,18,3]\n",
    "# #raw responses: domain=social?\n",
    "# raw_vars_social=[1,1,1,1,0,1]\n",
    "# raw_vars_social_map = dict(zip(raw_vars, raw_vars_social))\n",
    "# #raw responses: domain=cognitive?\n",
    "# raw_vars_cognitive=[0]*6\n",
    "# raw_vars_cognitive_map = dict(zip(raw_vars, raw_vars_cognitive))\n",
    "# #raw responses: replicating know human bias?\n",
    "# raw_vars_known=[0]*6\n",
    "# raw_vars_known_map = dict(zip(raw_vars, raw_vars_known))\n",
    "# #raw responses: preference measure?\n",
    "# raw_vars_pref=[1,1,0,0,0,0]\n",
    "# raw_vars_pref_map = dict(zip(raw_vars, raw_vars_pref))\n",
    "# #raw responses: stimuli dependent?\n",
    "# raw_vars_stim=[0]*6\n",
    "# raw_vars_stim_map = dict(zip(raw_vars, raw_vars_stim))\n",
    "\n",
    "# DVs:\n",
    "DV_vars = [\n",
    "    \"Redistribution 1\",\n",
    "    \"Redistribution 2\",\n",
    "    \"Fairness\",\n",
    "    \"Work vs Luck\",\n",
    "    \"Father education\",\n",
    "    \"Trust\",\n",
    "]\n",
    "DV_vars_min = [1, 1, 1, 1, 10, 1]\n",
    "DV_vars_max = [5, 5, 3, 3, 18, 3]\n",
    "# DVs: domain=social?\n",
    "DV_vars_social = [1, 1, 1, 1, 0, 1]\n",
    "DV_vars_social_map = dict(zip(DV_vars, DV_vars_social))\n",
    "# DVs: domain=cognitive?\n",
    "DV_vars_cognitive = [0] * 6\n",
    "DV_vars_cognitive_map = dict(zip(DV_vars, DV_vars_cognitive))\n",
    "# DVs: replicating know human bias?\n",
    "DV_vars_known = [0] * 6\n",
    "DV_vars_known_map = dict(zip(DV_vars, DV_vars_known))\n",
    "# DVs: preference measure?\n",
    "DV_vars_pref = [1, 1, 0, 0, 0, 0]\n",
    "DV_vars_pref_map = dict(zip(DV_vars, DV_vars_pref))\n",
    "# DVs: stimuli dependent?\n",
    "DV_vars_stim = [0] * 6\n",
    "DV_vars_stim_map = dict(zip(DV_vars, DV_vars_stim))\n",
    "# DVs: knowledge question?\n",
    "DV_vars_know = [0] * 6\n",
    "DV_vars_know_map = dict(zip(DV_vars, DV_vars_know))\n",
    "# DVs: political question?\n",
    "DV_vars_politics = [1, 1, 0, 0, 0, 0]\n",
    "DV_vars_politics_map = dict(zip(DV_vars, DV_vars_politics))\n",
    "\n",
    "\n",
    "# merging key\n",
    "merge_key = [\"TWIN_ID\"]\n",
    "\n",
    "# Merge on TWIN_ID\n",
    "df = pd.merge(df_human, df_twin, on=merge_key, suffixes=(\"_human\", \"_twin\"))\n",
    "\n",
    "# Fix dtypes\n",
    "# for var in raw_vars + DV_vars:\n",
    "for var in DV_vars:\n",
    "    df[f\"{var}_human\"] = pd.to_numeric(df[f\"{var}_human\"], errors=\"coerce\")\n",
    "    df[f\"{var}_twin\"] = pd.to_numeric(df[f\"{var}_twin\"], errors=\"coerce\")\n",
    "\n",
    "# build min/max maps from both raw_vars and DV_vars\n",
    "min_map = {v: mn for v, mn in zip(DV_vars, DV_vars_min)}\n",
    "# min_map = {v: mn for v, mn in zip(raw_vars,      raw_vars_min)}\n",
    "# min_map.update({v: mn for v, mn in zip(DV_vars,   DV_vars_min)})\n",
    "\n",
    "max_map = {v: mx for v, mx in zip(DV_vars, DV_vars_max)}\n",
    "# max_map = {v: mx for v, mx in zip(raw_vars,      raw_vars_max)}\n",
    "# max_map.update({v: mx for v, mx in zip(DV_vars,   DV_vars_max)})\n",
    "\n",
    "# now add _min and _max columns for every variable in the union\n",
    "for var in min_map:\n",
    "    df[f\"{var}_min\"] = min_map[var]\n",
    "    df[f\"{var}_max\"] = max_map[var]\n",
    "\n",
    "# Compute results\n",
    "results = []\n",
    "# for var in raw_vars:\n",
    "#     col_h = f\"{var}_human\"\n",
    "#     col_t = f\"{var}_twin\"\n",
    "#     min_col = f\"{var}_min\"\n",
    "#     max_col = f\"{var}_max\"\n",
    "#     if cond_exists:\n",
    "#         cols = [col_h, col_t, cond_h, cond_t,min_col,max_col]\n",
    "#     else:\n",
    "#         cols = [col_h, col_t,min_col,max_col]\n",
    "#     pair = (\n",
    "#     df[cols]\n",
    "#       .dropna(subset=[col_h, col_t])\n",
    "#     )\n",
    "#     min_val = pair[min_col].iloc[0]\n",
    "#     max_val = pair[max_col].iloc[0]\n",
    "#     n    = len(pair)\n",
    "#     if n >= 4:\n",
    "#         r, _    = pearsonr(pair[col_h], pair[col_t])\n",
    "#         z_f     = np.arctanh(r)\n",
    "#         se      = 1 / np.sqrt(n - 3)\n",
    "#         z_crit  = norm.ppf(0.975)\n",
    "#         lo_z, hi_z = z_f - z_crit*se, z_f + z_crit*se\n",
    "#         lo_r, hi_r = np.tanh(lo_z), np.tanh(hi_z)\n",
    "#         z_score    = z_f / se\n",
    "#         # Accuracy = mean absolute diff / range\n",
    "#         if pd.isna(min_val) or pd.isna(max_val) or max_val == min_val:\n",
    "#             accuracy = np.nan\n",
    "#         else:\n",
    "#             # compute mean absolute difference\n",
    "#             abs_diff      = np.abs(pair[col_h] - pair[col_t])\n",
    "#             mean_abs_diff = abs_diff.mean()\n",
    "#             accuracy      = 1 - mean_abs_diff / (max_val - min_val)\n",
    "\n",
    "#         mean_h = pair[col_h].mean()\n",
    "#         mean_t = pair[col_t].mean()\n",
    "\n",
    "#         # Paired t‐test\n",
    "#         t_stat, p_val = ttest_rel(pair[col_h], pair[col_t])\n",
    "\n",
    "#         std_h = pair[col_h].std(ddof=1)\n",
    "#         std_t = pair[col_t].std(ddof=1)\n",
    "\n",
    "#          # F‐test for equal variances\n",
    "#         df1 = df2 = n - 1\n",
    "#         f_stat = (std_h**2 / std_t**2) if std_t>0 else np.nan\n",
    "\n",
    "#         # two‐tailed p‐value:\n",
    "#         if not np.isnan(f_stat):\n",
    "#             p_f = 2 * min(f.cdf(f_stat, df1, df2),\n",
    "#                           1 - f.cdf(f_stat, df1, df2))\n",
    "#         else:\n",
    "#             p_f = np.nan\n",
    "\n",
    "#         # Effect sizes (Cohen's d) across conditions\n",
    "#         #    For humans:\n",
    "#         if cond_exists and len(pair)>3:\n",
    "#             levels_h = pair[cond_h].unique()\n",
    "#             if len(levels_h) == 2:\n",
    "#                 g1 = pair.loc[pair[cond_h]==levels_h[0], col_h]\n",
    "#                 g2 = pair.loc[pair[cond_h]==levels_h[1], col_h]\n",
    "#                 n1, n2 = len(g1), len(g2)\n",
    "#                 # pooled sd\n",
    "#                 s_pool = np.sqrt(((n1-1)*g1.var(ddof=1)+(n2-1)*g2.var(ddof=1)) / (n1+n2-2))\n",
    "#                 d_human = (g1.mean() - g2.mean()) / s_pool if s_pool>0 else np.nan\n",
    "#             else:\n",
    "#                 d_human = np.nan\n",
    "#         else:\n",
    "#             d_human = np.nan\n",
    "\n",
    "#         #    For twins:\n",
    "#         if cond_exists and len(pair)>3:\n",
    "#             levels_t = pair[cond_t].unique()\n",
    "#             if cond_exists and len(levels_t) == 2:\n",
    "#                 g1 = pair.loc[pair[cond_t]==levels_t[0], col_t]\n",
    "#                 g2 = pair.loc[pair[cond_t]==levels_t[1], col_t]\n",
    "#                 n1, n2 = len(g1), len(g2)\n",
    "#                 s_pool = np.sqrt(((n1-1)*g1.var(ddof=1)+(n2-1)*g2.var(ddof=1)) / (n1+n2-2))\n",
    "#                 d_twin = (g1.mean() - g2.mean()) / s_pool if s_pool>0 else np.nan\n",
    "#             else:\n",
    "#                 d_twin = np.nan\n",
    "#         else:\n",
    "#             d_twin = np.nan\n",
    "#     else:\n",
    "#         r = lo_r = hi_r = z_score = accuracy = mean_h = mean_t = t_stat = p_val = std_h = std_t = f_stat = p_f = np.nan\n",
    "#         d_human = d_twin = np.nan\n",
    "\n",
    "\n",
    "#     results.append({\n",
    "#         'study name': study_name,\n",
    "#         'variable name': var,\n",
    "#         'variable type (raw response/DV)':     'raw',\n",
    "#         'correlation between the responses from humans vs. their twins':        r,\n",
    "#         'CI_lower': lo_r,\n",
    "#         'CI_upper': hi_r,\n",
    "#         'z-score for correlation between humans vs. their twins':  z_score,\n",
    "#         'accuracy between humans vs. their twins': accuracy,\n",
    "#         'mean_human': mean_h,\n",
    "#         'mean_twin': mean_t,\n",
    "#         'paired t-test t-stat': t_stat,\n",
    "#         'paired t-test p-value': p_val,\n",
    "#         'std_human': std_h,\n",
    "#         'std_twin': std_t,\n",
    "#         'variance test F-stat': f_stat,\n",
    "#         'variance test p-value': p_f,\n",
    "#         'effect size based on human': d_human,\n",
    "#         'effect size based on twin': d_twin,\n",
    "#         'domain=social?':raw_vars_social_map.get(var, np.nan),\n",
    "#         'domain=cognitive?':raw_vars_cognitive_map.get(var, np.nan),\n",
    "#         'replicating know human bias?':raw_vars_known_map.get(var, np.nan),\n",
    "#         'preference measure?':raw_vars_pref_map.get(var, np.nan),\n",
    "#         'stimuli dependent?':raw_vars_stim_map.get(var, np.nan),\n",
    "#         'sample size':        n\n",
    "#     })\n",
    "\n",
    "for var in DV_vars:\n",
    "    col_h = f\"{var}_human\"\n",
    "    col_t = f\"{var}_twin\"\n",
    "    min_col = f\"{var}_min\"\n",
    "    max_col = f\"{var}_max\"\n",
    "    if cond_exists:\n",
    "        cols = [col_h, col_t, cond_h, cond_t, min_col, max_col]\n",
    "    else:\n",
    "        cols = [col_h, col_t, min_col, max_col]\n",
    "    pair = df[cols].dropna(subset=[col_h, col_t])\n",
    "    min_val = pair[min_col].iloc[0]\n",
    "    max_val = pair[max_col].iloc[0]\n",
    "    n = len(pair)\n",
    "    if n >= 4:\n",
    "        r, _ = pearsonr(pair[col_h], pair[col_t])\n",
    "        z_f = np.arctanh(r)\n",
    "        se = 1 / np.sqrt(n - 3)\n",
    "        z_crit = norm.ppf(0.975)\n",
    "        lo_z, hi_z = z_f - z_crit * se, z_f + z_crit * se\n",
    "        lo_r, hi_r = np.tanh(lo_z), np.tanh(hi_z)\n",
    "        z_score = z_f / se\n",
    "        # Accuracy = mean absolute diff / range\n",
    "        if pd.isna(min_val) or pd.isna(max_val) or max_val == min_val:\n",
    "            accuracy = np.nan\n",
    "        else:\n",
    "            # compute mean absolute difference\n",
    "            abs_diff = np.abs(pair[col_h] - pair[col_t])\n",
    "            mean_abs_diff = abs_diff.mean()\n",
    "            accuracy = 1 - mean_abs_diff / (max_val - min_val)\n",
    "\n",
    "        mean_h = pair[col_h].mean()\n",
    "        mean_t = pair[col_t].mean()\n",
    "\n",
    "        # Paired t‐test\n",
    "        t_stat, p_val = ttest_rel(pair[col_h], pair[col_t])\n",
    "\n",
    "        std_h = pair[col_h].std(ddof=1)\n",
    "        std_t = pair[col_t].std(ddof=1)\n",
    "\n",
    "        # F‐test for equal variances\n",
    "        df1 = df2 = n - 1\n",
    "        f_stat = (std_h**2 / std_t**2) if std_t > 0 else np.nan\n",
    "        # two‐tailed p‐value:\n",
    "        if not np.isnan(f_stat):\n",
    "            p_f = 2 * min(f.cdf(f_stat, df1, df2), 1 - f.cdf(f_stat, df1, df2))\n",
    "        else:\n",
    "            p_f = np.nan\n",
    "\n",
    "        # Effect sizes (Cohen's d) across conditions\n",
    "        #    For humans:\n",
    "        if cond_exists and len(pair) > 3:\n",
    "            levels_h = pair[cond_h].unique()\n",
    "            if len(levels_h) == 2:\n",
    "                g1 = pair.loc[pair[cond_h] == levels_h[0], col_h]\n",
    "                g2 = pair.loc[pair[cond_h] == levels_h[1], col_h]\n",
    "                n1, n2 = len(g1), len(g2)\n",
    "                # pooled sd\n",
    "                s_pool = np.sqrt(\n",
    "                    ((n1 - 1) * g1.var(ddof=1) + (n2 - 1) * g2.var(ddof=1)) / (n1 + n2 - 2)\n",
    "                )\n",
    "                d_human = (g1.mean() - g2.mean()) / s_pool if s_pool > 0 else np.nan\n",
    "            else:\n",
    "                d_human = np.nan\n",
    "        else:\n",
    "            d_human = np.nan\n",
    "\n",
    "        #    For twins:\n",
    "        if cond_exists and len(pair) > 3:\n",
    "            levels_t = pair[cond_t].unique()\n",
    "            if cond_exists and len(levels_t) == 2:\n",
    "                g1 = pair.loc[pair[cond_t] == levels_t[0], col_t]\n",
    "                g2 = pair.loc[pair[cond_t] == levels_t[1], col_t]\n",
    "                n1, n2 = len(g1), len(g2)\n",
    "                s_pool = np.sqrt(\n",
    "                    ((n1 - 1) * g1.var(ddof=1) + (n2 - 1) * g2.var(ddof=1)) / (n1 + n2 - 2)\n",
    "                )\n",
    "                d_twin = (g1.mean() - g2.mean()) / s_pool if s_pool > 0 else np.nan\n",
    "            else:\n",
    "                d_twin = np.nan\n",
    "        else:\n",
    "            d_twin = np.nan\n",
    "    else:\n",
    "        r = lo_r = hi_r = z_score = accuracy = mean_h = mean_t = t_stat = p_val = std_h = std_t = (\n",
    "            f_stat\n",
    "        ) = p_f = np.nan\n",
    "        d_human = d_twin = np.nan\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"study name\": study_name,\n",
    "            \"persona specification\": specification_name,\n",
    "            \"variable name\": var,\n",
    "            #        'variable type (raw response/DV)':     'DV',\n",
    "            \"correlation between the responses from humans vs. their twins\": r,\n",
    "            \"CI_lower\": lo_r,\n",
    "            \"CI_upper\": hi_r,\n",
    "            \"z-score for correlation between humans vs. their twins\": z_score,\n",
    "            \"accuracy between humans vs. their twins\": accuracy,\n",
    "            \"mean_human\": mean_h,\n",
    "            \"mean_twin\": mean_t,\n",
    "            \"paired t-test t-stat\": t_stat,\n",
    "            \"paired t-test p-value\": p_val,\n",
    "            \"std_human\": std_h,\n",
    "            \"std_twin\": std_t,\n",
    "            \"variance test F-stat\": f_stat,\n",
    "            \"variance test p-value\": p_f,\n",
    "            \"effect size based on human\": d_human,\n",
    "            \"effect size based on twin\": d_twin,\n",
    "            \"domain=social?\": DV_vars_social_map.get(var, np.nan),\n",
    "            \"domain=cognitive?\": DV_vars_cognitive_map.get(var, np.nan),\n",
    "            \"replicating know human bias?\": DV_vars_known_map.get(var, np.nan),\n",
    "            \"preference measure?\": DV_vars_pref_map.get(var, np.nan),\n",
    "            \"stimuli dependent?\": DV_vars_stim_map.get(var, np.nan),\n",
    "            \"knowledge question?\": DV_vars_know_map.get(var, np.nan),\n",
    "            \"political question?\": DV_vars_politics_map.get(var, np.nan),\n",
    "            \"sample size\": n,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# results DataFrame\n",
    "corr_df = pd.DataFrame(results)\n",
    "print(corr_df)\n",
    "\n",
    "# save output as csv - unit of observation is comparison between humans and twins:\n",
    "out_file = f\"{study_name} {specification_name} meta analysis.csv\"\n",
    "corr_df.to_csv(out_file, index=False)\n",
    "\n",
    "\n",
    "#####participant-level data:\n",
    "def make_long(df, respondent_type):\n",
    "    # pick off TWIN_ID + the DVs, then melt\n",
    "    long = df[[\"TWIN_ID\"] + DV_vars].melt(\n",
    "        id_vars=\"TWIN_ID\", value_vars=DV_vars, var_name=\"variable_name\", value_name=\"value\"\n",
    "    )\n",
    "\n",
    "    long[\"respondent_type\"] = respondent_type\n",
    "    long[\"study_name\"] = study_name\n",
    "    long[\"specification_name\"] = specification_name\n",
    "    return long\n",
    "\n",
    "\n",
    "# build the two halves\n",
    "long_h = make_long(df_human, \"human\")\n",
    "long_t = make_long(df_twin, \"twin\")\n",
    "\n",
    "# stack them\n",
    "df_long = pd.concat([long_h, long_t], ignore_index=True)\n",
    "\n",
    "print(df_long.head())\n",
    "# save output as csv - unit of observation is TWIN_ID:\n",
    "out_file = f\"{study_name} {specification_name} meta analysis individual level.csv\"\n",
    "df_long.to_csv(out_file, index=False)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef87075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
